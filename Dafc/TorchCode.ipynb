{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilik Torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 14:16:50.177330: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 14:16:50.723144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import pickle\n",
    "import mlflow\n",
    "import logging\n",
    "import argparse\n",
    "import datetime\n",
    "import commentjson\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "from bunch import Bunch\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "import torch.functional as F\n",
    "from torch.nn.functional import pad\n",
    "from collections import OrderedDict\n",
    "logger = logging.getLogger(\"logger\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define Config class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_VERBOSE_WAIVER = ['save_model', 'tracking_uri', 'quiet', 'sim_dir', 'train_writer', 'test_writer', 'valid_writer']\n",
    "class Config(Bunch):\n",
    "    \"\"\" class for handling dicrionary as class attributes \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def print(self):\n",
    "        line_len = 122\n",
    "        line = \"-\" * line_len\n",
    "        logger.info(line + \"\\n\" +\n",
    "              \"| {:^35s} | {:^80} |\\n\".format('Feature', 'Value') +\n",
    "              \"=\" * line_len)\n",
    "        for key, val in sorted(self.items(), key= lambda x: x[0]):\n",
    "            if isinstance(val, OrderedDict):\n",
    "                raise NotImplementedError(\"Nested configs are not implemented\")\n",
    "            else:\n",
    "                if key not in CONFIG_VERBOSE_WAIVER:\n",
    "                    logger.info(\"| {:35s} | {:80} |\\n\".format(key, str(val)) + line)\n",
    "        logger.info(\"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(argv):\n",
    "    argparser = argparse.ArgumentParser(description=__doc__)\n",
    "    argparser.add_argument('--config', default=None, type=str, help='path to config file')\n",
    "    argparser.add_argument('--seed', default=None, type=int, help='randomization seed')\n",
    "    argparser.add_argument('--exp_name', default=None, type=int, help='Experiment name')\n",
    "    argparser.add_argument('--num_targets', default=None, type=int, help='Number of simulated targets')\n",
    "    argparser.set_defaults(quiet=False)\n",
    "    args, unknown = argparser.parse_known_args(argv)\n",
    "    #args = argparser.parse_args()\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_to_dict(fname):\n",
    "    \"\"\" read json config file into ordered-dict \"\"\"\n",
    "    fname = Path(fname)\n",
    "    with fname.open('rt') as handle:\n",
    "        config_dict = commentjson.load(handle, object_hook=OrderedDict)\n",
    "        return config_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(args):\n",
    "    \"\"\" read config from json file and update by the command line arguments \"\"\"\n",
    "    if args.config is not None:\n",
    "        json_file = args.config\n",
    "    else:\n",
    "        json_file = \"/home/leshkar/Desktop/BGU/configs/config.json\"  # Replace with your default config file path\n",
    "\n",
    "    config_dict = read_json_to_dict(json_file)\n",
    "    config = Config(config_dict)\n",
    "\n",
    "    for arg in sorted(vars(args)):\n",
    "        key = arg\n",
    "        val = getattr(args, arg)\n",
    "        if val is not None:\n",
    "            setattr(config, key, val)\n",
    "\n",
    "    if args.seed is None and config.seed is None:\n",
    "        \n",
    "        MAX_SEED = sys.maxsize\n",
    "        config.seed = randint(0, MAX_SEED)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_init():\n",
    "    \"\"\"Allows GPU memory growth\"\"\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cuda.autotune = True\n",
    "        torch.backends.cudnn.enabled = True\n",
    "\n",
    "    return device\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger and tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger_and_tracker(config):\n",
    "    ''' configure the mlflow tracker:\n",
    "        1. set tracking location (uri)\n",
    "        2. configure exp name/id\n",
    "        3. define parameters to be documented\n",
    "    '''\n",
    "\n",
    "    config.exp_name_time = \"{}_{}_{}\".format(config.exp_name,datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),config.seed)\n",
    "    config.tensor_board_dir = os.path.join('..',\n",
    "                                           'results',\n",
    "                                           config.exp_name,\n",
    "                                           config.exp_name_time)\n",
    "\n",
    "    if not os.path.exists(config.tensor_board_dir):\n",
    "        os.makedirs(config.tensor_board_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scripts(config,SRC_DIR):\n",
    "    path = os.path.join(config.tensor_board_dir, 'scripts')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    scripts_to_save = glob.glob('{}/**/*.py'.format(SRC_DIR), recursive=True) + [config.config]\n",
    "    scripts_to_save = [script for script in scripts_to_save if '{}/results'.format(SRC_DIR) not in script]\n",
    "    if scripts_to_save is not None:\n",
    "        for script in scripts_to_save:\n",
    "            dst_file = os.path.join(path, os.path.basename(script))\n",
    "            try:\n",
    "                shutil.copyfile(os.path.join(os.path.dirname(sys.argv[0]), script), dst_file)\n",
    "            except:\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config(config):\n",
    "    print('')\n",
    "    print('#' * 70)\n",
    "    print('Configurations at beginning of run')\n",
    "    print('#' * 70)\n",
    "    for key in config.keys():\n",
    "        print('{}, {}'.format(key,config['{}'.format(key)]))\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate Conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Configurations at beginning of run\n",
      "######################################################################\n",
      "model_input_dim, [None]\n",
      "model_output_dim, 1\n",
      "quiet, False\n",
      "seed, 6477700957040699125\n",
      "exp_name, temp\n",
      "load_complete_model, False\n",
      "load_model_path, \n",
      "con_inf_rng_path, \n",
      "con_inf_vel_path, \n",
      "eval_model_pth, \n",
      "detection_pfa_miss_M_valid, 5000\n",
      "detection_exp_type, pd\n",
      "ipix_pkl_path, \n",
      "ipix_pkl_path_dir, /home/leshkar/Desktop/RD_NN-main/datasets/IPIX/15m/pkl/hh\n",
      "ipix_pkl_cv_hold_out, \n",
      "ipix_cdf_files_list, []\n",
      "ipix_skip_cv_iters, []\n",
      "ipix_predefined_cv_iters, []\n",
      "ipix_cv_mode, False\n",
      "ipix_cv_script, main_train\n",
      "ipix_cv_rng_pth, ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng_2022-03-12_17-29-13_405075\n",
      "ipix_cv_vel_pth, ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel_2022-03-12_09-02-17_826518\n",
      "sweep_run_eval_con_inf, False\n",
      "sweep_run_eval, True\n",
      "sweep_dict, OrderedDict([('mc_iteration', True), ('num_targets', False), ('learning_rate', False), ('activation', False), ('batch_size', False), ('l2_reg_parameter', False), ('dense_sizes', False), ('two_stage_fc_dims', False), ('two_stage_fc_dense_sizes', False), ('two_stage_fc_use_batch_norm', False), ('two_stage_fc_dropout_rate', False), ('CBBCE_predefined_weight', False), ('point_cloud_reconstruction_CBBCE_gaussian_smoothing_std', False), ('point_cloud_reconstruction_dim', False), ('use_lr_scheduler', False), ('use_lr_scheduler_deriv', False), ('cfar_window_size', False), ('beamforming_method', False), ('cfar_os_order_statistic', False), ('cfar_num_censor_cells_largest', False), ('augment_list', False), ('dummy_config', False), ('mvdr_loading_factor', False)])\n",
      "mc_iteration_sweep_list, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "num_targets_sweep_list, [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "learning_rate_sweep_list, [0.01, 0.001]\n",
      "scale_sweep_list, [0.5, 1, 2]\n",
      "data_merge_size_sweep_list, [0.25, 0.5, 0.75]\n",
      "l2_reg_parameter_sweep_list, [0.1, 0.01, 0.001, 0.0001, 1e-05]\n",
      "activation_sweep_list, ['relu', 'tanh']\n",
      "beamforming_method_sweep_list, ['MVDR', 'MUSIC', 'MLE']\n",
      "batch_size_sweep_list, [32, 64, 128, 256, 512]\n",
      "dense_sizes_sweep_list, [[2048, 1024, 512], [256, 512, 1024, 512], [2048, 1024, 512, 256], [256, 1024, 4096, 512], [256, 2048, 1024, 512], [256, 512, 2048, 1024, 256, 64], [512, 2048, 256, 32], [256, 1024, 128, 32]]\n",
      "nnmvdr_fc_encoder_dim_sweep_list, [128, 64, 16, 8, 4]\n",
      "two_stage_fc_use_batch_norm_sweep_list, [[False, False, False], [True, True, True], [True, False, True], [False, True, False]]\n",
      "two_stage_fc_dropout_rate_sweep_list, [[0.0, 0.0, 0.0], [0.0, 0.25, 0.0], [0.0, 0.5, 0.0], [0.25, 0.0, 0.25], [0.5, 0.5, 0.5]]\n",
      "two_stage_fc_dims_sweep_list, [[[32, 128], [128, 1024], [256, 2048], [64, 512], [16, 256]], [[32, 64], [128, 512], [64, 256], [8, 128]], [[64, 128], [128, 512], [32, 256], [16, 128]], [[128, 1024], [16, 256], [8, 128], [2, 32]], [[128, 1024], [16, 256], [4, 128]]]\n",
      "two_stage_fc_dense_sizes_sweep_list, [[128, 32], [512, 256, 128], [1024, 256], [512, 64]]\n",
      "point_cloud_reconstruction_dim_sweep_list, [32, 64, 128, 256]\n",
      "use_lr_scheduler_sweep_list, [True, False]\n",
      "use_lr_scheduler_deriv_sweep_list, [True, False]\n",
      "cfar_window_size_sweep_list, [[0.2, 0.2, 0.2], [0.15, 0.15, 0.15], [0.1, 0.1, 0.1], [0.05, 0.05, 0.05]]\n",
      "cfar_os_order_statistic_sweep_list, [0.25, 0.5, 0.75]\n",
      "cfar_num_censor_cells_largest_sweep_list, [0.1, 0.25, 0.5, 0.75]\n",
      "mvdr_loading_factor_sweep_list, [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 10.0, 15.0]\n",
      "dummy_config_sweep_list, ['']\n",
      "data_name, ipix\n",
      "ipix_max_nrange_bins, 27\n",
      "ipix_file_range_bins, True\n",
      "ipix_random_shift_doppler, True\n",
      "random_num_targets, True\n",
      "num_targets, 8\n",
      "M_train, 10000\n",
      "M_valid, 1000\n",
      "M_test, 10000\n",
      "without_target_ratio, 1.0\n",
      "without_target_ratio_test, 0.5\n",
      "N, 64\n",
      "K, 64\n",
      "L, 10\n",
      "FOV, 60\n",
      "SCNR_db, -5\n",
      "B_chirp, 50000000.0\n",
      "f_s, 1000000.0\n",
      "T_idle, 5e-05\n",
      "compound_gaussian_add_wgn, False\n",
      "compound_gaussian_dims, 2\n",
      "compound_gaussian_single_clutter_vel, True\n",
      "compound_gaussian_constant_clutter_vel, None\n",
      "random_SCNR, True\n",
      "SCNR_db_range, [-5, 10]\n",
      "SCNR_db_random_choice, False\n",
      "SCNR_db_random_constant, False\n",
      "SCNRs_eval, [-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10]\n",
      "compound_gaussian_gamma_shapes_eval, [0.5]\n",
      "sigma_f, 0.05\n",
      "compound_gaussian_random_gamma_shape, True\n",
      "gamma_shape_range, [0.1, 1.5]\n",
      "gamma_shape, 0.25\n",
      "T_PRI, 0.001\n",
      "CNR_db, 15\n",
      "signal_random_phase, True\n",
      "signal_physical_phase, True\n",
      "embedded_target, False\n",
      "embedded_target_vel_offset, 1.0\n",
      "embedded_target_azm_offset, 10.0\n",
      "v_r_min, -7.5\n",
      "v_r_max, 7.5\n",
      "v_0_min, -7.5\n",
      "v_0_max, 7.5\n",
      "r_0_min, 0\n",
      "r_0_max, 465\n",
      "f_c, 9390000000.0\n",
      "cfar_method, ca\n",
      "cfar_num_censor_cells_largest, 0.25\n",
      "cfar_num_censor_cells_smallest, 0.25\n",
      "cfar_os_order_statistic, 0.5\n",
      "cfar_single_param, []\n",
      "cfar_guard_cell, [0.1, 0.1, 0.1]\n",
      "cfar_window_size, [0.1, 0.1, 0.1]\n",
      "fit_verbose, 2\n",
      "num_epochs, 300\n",
      "batch_size, 256\n",
      "optimizer, adam\n",
      "learning_rate, 0.001\n",
      "l2_reg_parameter, 0.0001\n",
      "activation, tanh\n",
      "leaky_alpha, 0.1\n",
      "stop_max_acc, False\n",
      "use_model_checkpoint_best, False\n",
      "model_checkpoint_best_metric, val_mse\n",
      "model_checkpoint_epoch_period, 5\n",
      "save_fit_history, True\n",
      "use_early_stop, True\n",
      "early_stop_metric, val_loss\n",
      "early_stop_patience, 0.3333\n",
      "early_stop_mode, min\n",
      "use_lr_scheduler, False\n",
      "lr_scheduler_decay, 0.905\n",
      "lr_scheduler_period, 5\n",
      "lr_scheduler_epoch_threshold, 0.4\n",
      "use_lr_scheduler_plateau, True\n",
      "lr_scheduler_plateau_decay, 0.905\n",
      "lr_scheduler_plateau_window, 10\n",
      "lr_scheduler_plateau_cooldown, 5\n",
      "lr_scheduler_plateau_epoch_threshold, 0.05\n",
      "use_lr_scheduler_deriv, False\n",
      "lr_deriv_decay, 0.905\n",
      "lr_deriv_min_delta, -0.0001\n",
      "lr_deriv_period, 4\n",
      "lr_deriv_epoch_threshold, 0.3\n",
      "save_final_model, True\n",
      "use_CBBCE, True\n",
      "CBBCE_penalize_interference, False\n",
      "CBBCE_use_penalize_margin, False\n",
      "CBBCE_use_penalize_snr, False\n",
      "CBBCE_penalize_snr_use_geom_space, False\n",
      "CBBCE_penalize_margin, 5\n",
      "CBBCE_predefined_weight, 0\n",
      "two_stage_fc_stdize, True\n",
      "estimation_params, ['vel']\n",
      "point_cloud_reconstruction_dim, 64\n",
      "point_cloud_reconstruction, True\n",
      "point_cloud_reconstruction_3d, False\n",
      "point_cloud_reconstruction_2d, False\n",
      "point_cloud_reconstruction_fft_dims, True\n",
      "point_cloud_reconstruction_fft_dim_factor, 1\n",
      "point_cloud_reconstruction_3d_margins, [3.0, 0.2496006389776358, 9.594]\n",
      "point_cloud_reconstruction_bin_guard_margin, [1, 1, 0]\n",
      "point_cloud_reconstruction_pFA_values, [1e-05, 5e-05, 0.0001, 0.0005, 0.001]\n",
      "con_inf_use_model_only, False\n",
      "con_inf_use_projection_only, False\n",
      "evaluation_sets, ['test']\n",
      "augment_prob, 0.5\n",
      "augment_list, []\n",
      "additive_noise_std, 1.0\n",
      "row_shift, 32\n",
      "col_shift, 32\n",
      "trainer_name, detection_classification\n",
      "mode, Detection\n",
      "model_name, Detection-TwoStage-FC\n",
      "dense_sizes, [2048, 1024, 512]\n",
      "dense_dropout, None\n",
      "fc_batchnorm, False\n",
      "two_stage_fc_dims, [[128, 1024], [16, 256], [4, 128]]\n",
      "two_stage_fc_use_batch_norm, [False, False, False, False, False, False, False, False, False, False]\n",
      "two_stage_fc_dropout_rate, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "two_stage_fc_dense_sizes, []\n",
      "two_stage_fc_dense_dropout, []\n",
      "two_stage_fc_dense_batchnorm, None\n",
      "two_stage_fc_use_gap, False\n",
      "dummy_config, \n",
      "mc_iteration, 0\n",
      "exp_name_time, temp_2023-06-26_14-16-51_6477700957040699125\n",
      "tensor_board_dir, ../results/temp/temp_2023-06-26_14-16-51_6477700957040699125\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SRC_DIR = os.getcwd()\n",
    "config_path = '/home/leshkar/Desktop/BGU/configs/config.json'  \n",
    "args = get_args(config_path)\n",
    "config = read_config(args)\n",
    "gpu_init()\n",
    "set_logger_and_tracker(config)\n",
    "#save_scripts(config,SRC_DIR)\n",
    "print_config(config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_compound_gaussian_pipeline_dataset(config, M0, M1):\n",
    "\n",
    "    def gen_frame2d(ind):\n",
    "        \"\"\"\n",
    "        1.  generate single fast-time x slow-time clutter matrix.\n",
    "            Each row is i.i.d by compound gaussian distribution distribution\n",
    "            config.sigma_f = clutter correlation factor, (how much the clutter is correlated between pulses)\n",
    "            clutter_fd = clutter Doppler frequency\n",
    "        2.  generate single fast-time x slow-time white gaussian noise matrix.\n",
    "        3.  generate single fast-time x slow-time target echo signal matrix.\n",
    "        \"\"\"\n",
    "        # generate clutter signal\n",
    "        if config.compound_gaussian_single_clutter_vel:\n",
    "            if config.compound_gaussian_constant_clutter_vel is not None:\n",
    "                clutter_vel = tf.constant([config.compound_gaussian_constant_clutter_vel], dtype=tf.float32)\n",
    "            else:\n",
    "                clutter_vel = tf.random.uniform([1], np.floor(config.v_r_min), np.floor(config.v_r_max))\n",
    "            clutter_fd = tf.cast(2 * np.pi * config.T_PRI * ((2 * config.f_c * clutter_vel) / 3e8), dtype=tf.complex128)\n",
    "            C = tf.math.exp(-2 * (config.sigma_f ** 2) * (np.pi ** 2) * (C_cords ** 2) - 1j * C_cords * clutter_fd)\n",
    "        else:\n",
    "            assert config.compound_gaussian_dims == 2\n",
    "            raise Exception('')\n",
    "        z_t = tf.cast(tf.random.normal([K, N_range_bins], mean=0.0, stddev=np.sqrt(0.5)), dtype=tf.complex128) + \\\n",
    "              1j * tf.cast(tf.random.normal([K, N_range_bins], mean=0.0, stddev=np.sqrt(0.5)), dtype=tf.complex128)\n",
    "        e, V = tf.linalg.eigh(C)\n",
    "        e_sqrt = tf.math.sqrt(tf.math.maximum(tf.math.real(e), 0.0))\n",
    "        E = tf.cast(tf.linalg.diag(e_sqrt), dtype=tf.complex128)\n",
    "        A = tf.matmul(V, E)\n",
    "        # [K, N_range_bins]\n",
    "        w_t = tf.matmul(A, z_t)\n",
    "        # create texture s ~ gamma(shape)\n",
    "        if config.compound_gaussian_random_gamma_shape:\n",
    "            gamma_shape = tf.gather(tf.random.uniform([1, ], minval=config.gamma_shape_range[0], maxval=config.gamma_shape_range[1] + 0.001), 0)\n",
    "        else:\n",
    "            gamma_shape = config.gamma_shape\n",
    "        s = tf.random.gamma([N_range_bins,], alpha=gamma_shape, beta=gamma_shape)\n",
    "        c_t = tf.cast(tf.expand_dims(tf.math.sqrt(s), 0), dtype=tf.complex128) * w_t\n",
    "        # \"insert\" clutter Doppler vector for each range bin\n",
    "        clutter_omega_r = ((2 * np.pi) / N) * tf.range(N_range_bins, dtype=tf.float32)\n",
    "        clutter_range_steering_tensor = tf.math.exp(-1j * tf.cast(tf.expand_dims(tf.range(N, dtype=tf.float32), -1) * tf.expand_dims(clutter_omega_r, 0), dtype=tf.complex128))\n",
    "        c_tensor = tf.matmul(c_t, tf.transpose(clutter_range_steering_tensor))\n",
    "        c_tensor = tf.transpose(c_tensor)\n",
    "\n",
    "        # generate WGN\n",
    "        n_tensor = tf.cast(tf.random.normal([K, N], mean=0.0, stddev=np.sqrt(0.5 * sigma2)), dtype=tf.complex128) + \\\n",
    "              1j * tf.cast(tf.random.normal([K, N], mean=0.0, stddev=np.sqrt(0.5 * sigma2)), dtype=tf.complex128)\n",
    "        n_tensor = tf.transpose(n_tensor)\n",
    "\n",
    "        # clutter velocity reconstruction label tensor\n",
    "        clutter_inds_vel = tf.expand_dims(tf.math.argmin(tf.abs(tf.expand_dims(clutter_vel, 1) - tf.expand_dims(recon_vec_vel, 0)), axis=1), 1)\n",
    "        clutter_label_tensor = tf.scatter_nd(tf.expand_dims(clutter_inds_vel, 1), tf.expand_dims(tf.ones_like(clutter_inds_vel), 1), (recon_vec_vel.shape[0], 1))\n",
    "\n",
    "        if not with_target:\n",
    "            param_val_tensor = tf.ones(config.num_targets) * -1000.0, tf.ones(config.num_targets) * -1000.0\n",
    "            return c_tensor + n_tensor, tf.zeros((recon_vec_rng.shape[0], recon_vec_vel.shape[0]), dtype=tf.int64), \\\n",
    "                   param_val_tensor, tf.ones(config.num_targets) * -1000.0, gamma_shape, clutter_vel, clutter_label_tensor\n",
    "        else:\n",
    "            # generate target signal\n",
    "            # clutter plus noise energy is: N*K*(N_range_bins + sigma2)\n",
    "            rd_signal, label_tensor, param_val_tensor, scnr_tensor = gen_target_matrix(config, tf.sqrt(N*K*(N_range_bins + sigma2)), clutter_vel, N, K, recon_vec_rng, recon_vec_vel)\n",
    "\n",
    "            return rd_signal + c_tensor + n_tensor, label_tensor, param_val_tensor, scnr_tensor, gamma_shape, clutter_vel, clutter_label_tensor\n",
    "\n",
    "    def get_tfds(M_tfds):\n",
    "        tfds = tf.data.Dataset.range(0, M_tfds)\n",
    "        if config.compound_gaussian_dims == 2:\n",
    "            tfds = tfds.map(gen_frame2d, num_parallel_calls=-1)\n",
    "        else:\n",
    "            raise Exception(' ')\n",
    "        return tfds\n",
    "\n",
    "    # parameters\n",
    "    assert config.compound_gaussian_dims == 2\n",
    "    assert not (config.SCNR_db_random_constant and config.SCNR_db_random_choice)\n",
    "    K = config.K\n",
    "    N = config.N\n",
    "    N_range_bins = N // 2\n",
    "    config.r_0_max = (N_range_bins - 1) * (3e8 / (2.0 * config.B_chirp))\n",
    "\n",
    "    # Clutter correlation matrix\n",
    "    C_mesh = tf.meshgrid(tf.range(K), tf.range(K))\n",
    "    C_cords = tf.cast(C_mesh[1] - C_mesh[0], dtype=tf.complex128)\n",
    "    # WGN variance, determined by CNR_db\n",
    "    CNR = 10.0 ** (config.CNR_db / 10.0)\n",
    "    sigma2 = N_range_bins / CNR\n",
    "    # reconstruction vector for label creation\n",
    "    recon_vec_rng = tf.cast(get_reconstruction_point_cloud_vec(config, param_ind=0), dtype=tf.float32)\n",
    "    recon_vec_vel = tf.cast(get_reconstruction_point_cloud_vec(config, param_ind=1), dtype=tf.float32)\n",
    "\n",
    "    # get target and non-target tfds\n",
    "    with_target = False\n",
    "    tfds0 = get_tfds(M0) # [complex_tensor, label_tensor, gamma_shape]\n",
    "    with_target = True\n",
    "    _res = gen_frame2d(0)\n",
    "    tfds1 = get_tfds(M1) # [complex_tensor, label_tensor, (rng_vals, vel_vals), SCNR_db, gamma_shape]\n",
    "    assert tfds1.element_spec[0] == tfds0.element_spec[0] and tfds1.element_spec[1] == tfds0.element_spec[1]\n",
    "    tfds = tfds1.concatenate(tfds0)\n",
    "    tfds = tfds.map(split_auxillary_structure)\n",
    "\n",
    "    return tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CompoundGaussianPipelineDataset(Dataset):\n",
    "    def __init__(self, config, M0, M1):\n",
    "        self.config = config\n",
    "        self.M0 = M0\n",
    "        self.M1 = M1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.M0 + self.M1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < self.M0:\n",
    "            with_target = False\n",
    "        else:\n",
    "            with_target = True\n",
    "\n",
    "        # Implement the logic to generate the data item based on the index and with_target value\n",
    "\n",
    "        return data_item\n",
    "\n",
    "def get_dataset_compound_gaussian(config, apply_tf_preprocess_pipe=True):\n",
    "    data = {}\n",
    "    M1_train = config.M_train\n",
    "    M0_train = int(config.M_train * config.without_target_ratio)\n",
    "    M1_valid = config.M_valid\n",
    "    M0_valid = int(config.M_valid * config.without_target_ratio_test)\n",
    "    M1_test = config.M_test\n",
    "    M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "\n",
    "    if config.embedded_target:\n",
    "        assert config.compound_gaussian_single_clutter_vel\n",
    "    data['train'] = CompoundGaussianPipelineDataset(config, M0_train, M1_train)\n",
    "    data['valid'] = CompoundGaussianPipelineDataset(config, M0_valid, M1_valid)\n",
    "    data['test'] = CompoundGaussianPipelineDataset(config, M0_test, M1_test)\n",
    "\n",
    "    if apply_tf_preprocess_pipe:\n",
    "        for set_type in ['train', 'valid', 'test']:\n",
    "            data[set_type] = torch_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 36 (4145474748.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    return data\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WGNPipelineDataset(Dataset):\n",
    "    def __init__(self, config, M0, M1):\n",
    "        self.config = config\n",
    "        self.M0 = M0\n",
    "        self.M1 = M1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.M0 + self.M1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < self.M0:\n",
    "            with_target = False\n",
    "        else:\n",
    "            with_target = True\n",
    "\n",
    "        # Implement the logic to generate the data item based on the index and with_target value\n",
    "\n",
    "        return data_item\n",
    "\n",
    "def get_dataset_wgn(config, apply_tf_preprocess_pipe=True):\n",
    "    data = {}\n",
    "    M1_train = config.M_train\n",
    "    M0_train = int(config.M_train * config.without_target_ratio)\n",
    "    M1_valid = config.M_valid\n",
    "    M0_valid = int(config.M_valid * config.without_target_ratio_test)\n",
    "    M1_test = config.M_test\n",
    "    M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "\n",
    "    data['train'] = WGNPipelineDataset(config, M0_train, M1_train)\n",
    "    data['valid'] = WGNPipelineDataset(config, M0_valid, M1_valid)\n",
    "    data['test'] = WGNPipelineDataset(config, M0_test, M1_test)\n",
    "\n",
    "    if apply_tf_preprocess_pipe:\n",
    "        # Apply any necessary preprocessing using PyTorch transformations\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_output_dim(data, set_type):\n",
    "    if len(list(data['train'].element_spec[1].shape)) > 1:\n",
    "        return [list(data['train'].element_spec[1].shape)[0]]\n",
    "    if type(data[set_type].element_spec[1]) == type(tuple()):\n",
    "        return list(data[set_type].element_spec[1][0].shape)\n",
    "    else:\n",
    "        return [list(data[set_type].element_spec[1].shape)[0]]\n",
    "\n",
    "def get_model_input_dim(data, set_type):\n",
    "    if isinstance(data[set_type].element_spec[0], tuple):\n",
    "        model_input_dim = []\n",
    "        for spec in data[set_type].element_spec[0]:\n",
    "            model_input_dim.append(list(spec.shape))\n",
    "    else:\n",
    "        model_input_dim = list(data[set_type].element_spec[0].shape)\n",
    "\n",
    "    return model_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_iterators(data, config):\n",
    "    M_train = len(data['train'])\n",
    "    print('make_iterators(): M_train: {}'.format(M_train))\n",
    "    train_dataset = data['train'].shuffle(M_train, reshuffle_each_iteration=True)\n",
    "    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, drop_last=True, shuffle=True, num_workers=config.num_workers, pin_memory=True)\n",
    "    valid_iter = torch.utils.data.DataLoader(data['valid'], batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
    "    test_iter = torch.utils.data.DataLoader(data['test'], batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
    "    iterators = {'train': train_iter, 'valid': valid_iter, 'test': test_iter}\n",
    "    return iterators\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Valid Bins (range & velocity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The function takes a config, a 2D array shape, range and velocity bins arrays. filtering the velocity and range bins based on minimum and maximum values defined in the config.***\n",
    "\n",
    "***The function returns the filtered bin values along with their indices of the valid bins.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_2d_bins(config, full_shape, range_bins_values, vel_bins_values):\n",
    "    assert len(full_shape) == 2\n",
    "    vel_bins_values = torch.tensor(vel_bins_values)\n",
    "    range_bins_values = torch.tensor(range_bins_values)\n",
    "\n",
    "    valid_vel_bins = torch.nonzero(\n",
    "        (vel_bins_values >= config.v_0_min) & (vel_bins_values <= config.v_0_max)\n",
    "    ).squeeze()\n",
    "\n",
    "    if valid_vel_bins[-1] < full_shape[1] - 1:\n",
    "        valid_vel_bins = torch.cat((valid_vel_bins, torch.tensor([valid_vel_bins[-1] + 1])))\n",
    "\n",
    "    if valid_vel_bins[0] > 0:\n",
    "        valid_vel_bins = torch.cat((torch.tensor([valid_vel_bins[0] - 1]), valid_vel_bins))\n",
    "\n",
    "    vel_bins_values = vel_bins_values[valid_vel_bins]\n",
    "\n",
    "    valid_range_bins = torch.nonzero(\n",
    "        (range_bins_values >= config.r_0_min) & (range_bins_values <= config.r_0_max)\n",
    "    ).squeeze()\n",
    "\n",
    "    range_bins_values = range_bins_values[valid_range_bins]\n",
    "\n",
    "    return [range_bins_values, vel_bins_values], [valid_range_bins, valid_vel_bins]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCNR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***gets the signal to clutter plus noise ratio:***\n",
    "- if config.SCNR_db_random_choice, generates random integers between 0 and the length of config.SCNRs_eval. \n",
    "The SCNR values are gathered from SCNRs_eval using tf.gather() based on the indices in scnr_eval_inds\n",
    "- else if config.SCNR_db_random_constant, a single random SCNR value is chosen from config.SCNRs_eval and repeated for targets_num times.\n",
    "    scnr_eval_inds is generated to select a random index from config.SCNRs_eval.\n",
    "    \n",
    "    The selected SCNR value is multiplied by tf.ones(targets_num) to create a tensor of the same length as targets_num.\n",
    "    The SCNR values are assigned to SCNR_db.\n",
    "- if none of them so a constant SCNR value is used from config.SCNR_db, repeated for targets_num times.\n",
    "\n",
    "    The constant SCNR value is multiplied by tf.ones(targets_num) to create a tensor of the same length as targets_num.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_get_SCNR_db(config, targets_num):\n",
    "    if config.SCNR_db_random_choice:\n",
    "        SCNRs_eval = torch.tensor(config.SCNRs_eval, dtype=torch.float32)\n",
    "        scnr_eval_inds = torch.randint(0, len(config.SCNRs_eval), size=(targets_num,))\n",
    "        SCNR_db = SCNRs_eval[scnr_eval_inds]\n",
    "    elif config.SCNR_db_random_constant:\n",
    "        SCNRs_eval = torch.tensor(config.SCNRs_eval, dtype=torch.float32)\n",
    "        scnr_eval_inds = torch.randint(0, len(config.SCNRs_eval), size=(1,))\n",
    "        SCNR_db = SCNRs_eval[scnr_eval_inds] * torch.ones(targets_num)\n",
    "    elif config.random_SCNR:\n",
    "        SCNR_db = torch.FloatTensor(targets_num).uniform_(config.SCNR_db_range[0], config.SCNR_db_range[1] + 0.001)\n",
    "    else:\n",
    "        SCNR_db = torch.tensor(config.SCNR_db, dtype=torch.float32) * torch.ones(targets_num)\n",
    "    \n",
    "    return SCNR_db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split auxillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_auxillary_structure(mat_complex, mat_label, param_val, scnr, gamma_shape, clutter_vel, clutter_label_tensor):\n",
    "    return torch.squeeze(mat_complex), mat_label, (param_val, scnr, gamma_shape, clutter_vel, clutter_label_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_dataset_pipeline(config, data):\n",
    "    def two_stage_fc_preprocess(mat_complex, label):\n",
    "        mat = cube_center_and_reshape(mat_complex)\n",
    "        return mat, label\n",
    "    \n",
    "    def two_stage_fc_stdize(mat_complex, mat_label, aux):\n",
    "        mat_complex = mat_complex / mat_complex.std(dim=0, keepdim=True).to(torch.complex128)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    def two_stage_fc_preprocess_cg(mat_complex, mat_label, aux):\n",
    "        mat_complex, mat_label = two_stage_fc_preprocess(mat_complex, mat_label)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    def transpose_mat_complex(mat_complex, mat_label, aux):\n",
    "        mat_complex = mat_complex.transpose(0, 1)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    def concat_real_imag_cg(mat_complex, mat_label, aux):\n",
    "        return torch.cat((mat_complex.real, mat_complex.imag), dim=-1), mat_label, aux\n",
    "    \n",
    "    def preprocess_label2d(mat_label):\n",
    "        reduce_axis = 1 if config.estimation_params == [\"rng\"] else 0\n",
    "        mat_label = mat_label.sum(dim=reduce_axis).clamp(0, 1).to(torch.float32)\n",
    "        return mat_label\n",
    "    \n",
    "    def cg_preprocess_label_2dims(mat_complex, mat_label, aux):\n",
    "        mat_label = preprocess_label2d(mat_label)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    def cg_preprocess_label_1dim(mat_complex, mat_label, aux):\n",
    "        mat_label = mat_label.squeeze().clamp(0, 1).to(torch.float32)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    def cube_center_and_reshape(mat):\n",
    "        mat_center = mat - mat.view(-1, mat.shape[-1]).mean(dim=0)\n",
    "        return mat_center.view(-1, mat_center.shape[-1])\n",
    "    \n",
    "    if config.data_name == \"ipix\":\n",
    "        if config.model_name == \"Detection-TwoStage-FC\":\n",
    "            assert config.estimation_params == [\"rng\"] or config.estimation_params == [\"vel\"]\n",
    "            if config.estimation_params == [\"rng\"]:\n",
    "                data = data.map(transpose_mat_complex)\n",
    "            data = data.map(two_stage_fc_preprocess_cg)\n",
    "            if config.two_stage_fc_stdize:\n",
    "                data = data.map(two_stage_fc_stdize)\n",
    "            data = data.map(concat_real_imag_cg)\n",
    "            data = data.map(cg_preprocess_label_2dims)\n",
    "\n",
    "    if config.data_name == \"compound_gaussian\" or config.data_name == \"wgn\":\n",
    "        if config.model_name == \"Detection-TwoStage-FC\":\n",
    "            assert config.estimation_params == [\"rng\"] or config.estimation_params == [\"vel\"]\n",
    "            if config.estimation_params == [\"rng\"]:\n",
    "                data = data.map(transpose_mat_complex)\n",
    "            data = data.map(two_stage_fc_preprocess_cg)\n",
    "            if config.two_stage_fc_stdize:\n",
    "                data = data.map(two_stage_fc_stdize)\n",
    "            data = data.map(concat_real_imag_cg)\n",
    "            if config.compound_gaussian_dims == 2:\n",
    "                data = data.map(cg_preprocess_label_2dims)\n",
    "            else:\n",
    "                data = data.map(cg_preprocess_label_1dim)\n",
    "        elif config.model_name == \"Detection-FC\":\n",
    "            data = data.map(lambda t, label, aux: (torch.cat((t.real, t.imag), dim=0).squeeze(),\n",
    "                                                   label.squeeze().clamp(0, 1).to(torch.float32), aux))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and label tensors generator\n",
    "***This function generates a target matrix along with corresponding labels, parameter values, and SCNR tensors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target_matrix(config, cn_norm, clutter_vel_local, N, K, recon_vec_rng, recon_vec_vel):\n",
    "\n",
    "    # randomly determine the number of targets or set it to a constant value\n",
    "    if config.random_num_targets:\n",
    "        targets_num = torch.randint(1, config.num_targets + 1, (1,))\n",
    "    else:\n",
    "        targets_num = torch.tensor([config.num_targets], dtype=torch.int64)\n",
    "    \n",
    "    # Generate target velocities within specified range considering the presence of embedded targets\n",
    "    if config.embedded_target:\n",
    "        targets_vel = torch.empty(targets_num).uniform_(max(clutter_vel_local - config.embedded_target_vel_offset, config.v_0_min),\n",
    "                                                     min(clutter_vel_local + config.embedded_target_vel_offset, config.v_0_max))\n",
    "    else:\n",
    "        targets_vel = torch.empty(targets_num).uniform_(config.v_0_min, config.v_0_max)\n",
    "    \n",
    "    # Generate target ranges within specified range\n",
    "    targets_rng = torch.empty(targets_num).uniform_(config.r_0_min, config.r_0_max)\n",
    "    \n",
    "    # compute doppler and range target frequencies\n",
    "    targets_omega_d = torch.tensor(2 * np.pi * config.T_PRI * ((2 * config.f_c * targets_vel) / 3e8), dtype=torch.complex128)\n",
    "    targets_omega_r = torch.tensor(2 * np.pi * ((2 * config.B_chirp * targets_rng) / (3e8 * N)), dtype=torch.complex128)\n",
    "    \n",
    "    # compute doppler and range steering tensors\n",
    "    doppler_steering_tensor = torch.exp(-1j * targets_omega_d.unsqueeze(1) * torch.arange(K, dtype=torch.complex128))\n",
    "    range_steering_tensor = torch.exp(-1j * targets_omega_r.unsqueeze(1) * torch.arange(N, dtype=torch.complex128))\n",
    "    \n",
    "    # compute range-doppler signal and get the SCNR\n",
    "    rd_signal = range_steering_tensor.unsqueeze(2) * doppler_steering_tensor.unsqueeze(1)\n",
    "    SCNR_db = get_SCNR_db(config, targets_num)  # Assuming get_SCNR_db is defined\n",
    "    \n",
    "    # Adjust phase of the range-Doppler signal based on the configuration\n",
    "    if config.signal_random_phase:\n",
    "        rd_signal = rd_signal * torch.exp(1j * torch.empty(targets_num).uniform_(0, 2 * np.pi).unsqueeze(1).unsqueeze(1))\n",
    "    elif config.signal_physical_phase:\n",
    "        targets_tau0 = (2 * targets_rng) / 3e8\n",
    "        rd_signal = rd_signal * torch.exp(1j * (torch.tensor(-2 * np.pi * config.f_c * targets_tau0 + np.pi * (config.B_chirp / (config.N * config.f_s)) * (targets_tau0 ** 2), dtype=torch.complex128)).unsqueeze(1).unsqueeze(1))\n",
    "\n",
    "    # compensate for the appropriate SCNR level\n",
    "    s_norm = torch.norm(rd_signal, dim=[1, 2]).real\n",
    "    sig_amp = (10 ** (SCNR_db.float() / 20.0)) * (cn_norm.float() / s_norm)\n",
    "    rd_signal = torch.sum(sig_amp.unsqueeze(-1).unsqueeze(-1) * rd_signal, dim=0)\n",
    "    \n",
    "    # gen label vector\n",
    "    trgt_inds_vel = torch.argmin(torch.abs(targets_vel.unsqueeze(1) - recon_vec_vel.unsqueeze(0)), dim=1).unsqueeze(1)\n",
    "    trgt_inds_rng = torch.argmin(torch.abs(targets_rng.unsqueeze(1) - recon_vec_rng.unsqueeze(0)), dim=1).unsqueeze(1)\n",
    "    trgt_inds = torch.cat((trgt_inds_rng, trgt_inds_vel), dim=1)\n",
    "    label_tensor = torch.scatter(torch.zeros((recon_vec_rng.shape[0], recon_vec_vel.shape[0]), dtype=torch.float32), 0, trgt_inds, torch.ones_like(trgt_inds_vel).squeeze(1))\n",
    "\n",
    "    # gen parameter value and SCNR tensor\n",
    "    param_val_tensor = (torch.cat((targets_rng, torch.ones(config.num_targets - targets_num) * -1000.0), dim=0),\n",
    "                    torch.cat((targets_vel, torch.ones(config.num_targets - targets_num) * -1000.0), dim=0))\n",
    "    scnr_tensor = torch.cat((SCNR_db, torch.ones(config.num_targets - targets_num) * -1000.0), dim=0)\n",
    "\n",
    "    return rd_signal, label_tensor, param_val_tensor, scnr_tensor\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fft resolution\n",
    "calculates the resolutions and values for the range, velocity, and azimuth dimensions of the point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fft_resolutions(config, data_shape, T_PRI=None):\n",
    "    assert len(data_shape) == 4\n",
    "    T_PRI = data_shape[1] * (1 / config.f_s) + config.T_idle if T_PRI is None else T_PRI\n",
    "    vel_res = 3e8 / (2 * config.f_c * data_shape[2] * T_PRI)\n",
    "    range_res = 3e8 / (2 * config.B_chirp)\n",
    "    range_bins_values = torch.tensor([range_res * (i - data_shape[1] // 2) for i in range(data_shape[1])])\n",
    "    vel_bins_values = torch.tensor([vel_res * (i - data_shape[2] // 2) for i in range(data_shape[2])])\n",
    "\n",
    "    azimuth_bins_values = torch.tensor(np.arcsin([(2.0 * (i - data_shape[3] // 2)) / data_shape[3]\n",
    "                                          for i in range(data_shape[3])]) * (180.0 / np.pi))\n",
    "\n",
    "    return range_res, vel_res, range_bins_values, vel_bins_values, azimuth_bins_values\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### point cloud reconstraction\n",
    "calculates and returns vectors used for point cloud reconstruction in the ipix pipeline. \n",
    "the function first checks if we use FFT dimensions for point cloud reconstruction, If this option is enabled, it rescales the dimensions. This rescaling is done to achieve higher resolution in the reconstructed point cloud.\n",
    "\n",
    "The function then calls the get_fft_resolutions function to calculate the resolution and values for the range, velocity, and azimuth dimensions of the point cloud.\n",
    "\n",
    "If param_ind is 0, it returns the range bins values, which represent the distances from the radar sensor to the objects in the range dimension. If param_ind is 1, it returns the velocity bins values, representing the velocities of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_point_cloud_vec(config, param_ind):\n",
    "\n",
    "    if config.point_cloud_reconstruction_fft_dims:\n",
    "        N = config.point_cloud_reconstruction_fft_dim_factor * config.N\n",
    "        config.B_chirp = config.point_cloud_reconstruction_fft_dim_factor * config.B_chirp  # multiply to rescale range dimension\n",
    "        K = config.point_cloud_reconstruction_fft_dim_factor * config.K\n",
    "        L = config.point_cloud_reconstruction_fft_dim_factor * config.L\n",
    "\n",
    "        range_res, vel_res, recon_vec_rng, recon_vec, azimuth_bins_values = get_fft_resolutions(config, [1, N, K, L], T_PRI=config.T_PRI)\n",
    "        bin_values_list, valid_bins_list = get_valid_2d_bins(config, [N, K], recon_vec_rng, recon_vec)\n",
    "        range_bins_values = bin_values_list[0]\n",
    "        vel_bins_values = bin_values_list[1]\n",
    "\n",
    "        config.B_chirp = config.B_chirp / config.point_cloud_reconstruction_fft_dim_factor\n",
    "        if param_ind == 0:\n",
    "            return torch.tensor(range_bins_values)\n",
    "        elif param_ind == 1:\n",
    "            return torch.tensor(vel_bins_values)\n",
    "        else:\n",
    "            raise Exception('  ')\n",
    "    else:\n",
    "        raise Exception('get_reconstruction_point_cloud_res(): Unsupported...')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset pipeline generator\n",
    "generates a pipeline dataset for the \"ipix\" scenario. It processes the \"ipix\" data frames, applies random Doppler shifts (if enabled), generates radar signals and labels for target detection, and returns a dataset consisting of frames with and without targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ipix_pipeline_dataset(c_tensor_total, clutter_vel, config, M0, M1):\n",
    "    def gen_ipix_frame2d(ind):\n",
    "        c_tensor = c_tensor_total[:config.N, :config.K]\n",
    "        clutter_vel_local = clutter_vel\n",
    "        if config.ipix_random_shift_doppler:\n",
    "            shift_min = clutter_vel_local - config.v_r_min\n",
    "            shift_max = config.v_r_max - clutter_vel_local\n",
    "            doppler_shift_v = torch.FloatTensor(1).uniform_(-shift_min, shift_max)\n",
    "            clutter_vel_local = clutter_vel + doppler_shift_v.item()\n",
    "            shift_factor = torch.exp(-1j * 2 * np.pi * ((2 * config.f_c * doppler_shift_v) / 3e8) * config.T_PRI * torch.arange(c_tensor.shape[1]).to(torch.complex128))\n",
    "            c_tensor = c_tensor * shift_factor\n",
    "\n",
    "        if with_target is False:\n",
    "            param_val_tensor = (torch.ones(config.num_targets) * -1000.0, torch.ones(config.num_targets) * -1000.0)\n",
    "            return c_tensor, torch.zeros((recon_vec_rng.shape[0], recon_vec_vel.shape[0]), dtype=torch.int64), \\\n",
    "                   param_val_tensor, torch.ones(config.num_targets) * -1000.0, torch.tensor(0.0), clutter_vel_local, torch.tensor(0.0)\n",
    "        else:\n",
    "            cn_norm = torch.abs(torch.norm(c_tensor))\n",
    "            rd_signal, label_tensor, param_val_tensor, scnr_tensor = gen_target_matrix(config, cn_norm, clutter_vel_local, N, K, recon_vec_rng, recon_vec_vel)\n",
    "\n",
    "            return rd_signal + c_tensor, label_tensor, param_val_tensor, scnr_tensor, torch.tensor(0.0), clutter_vel_local, torch.tensor(0.0)\n",
    "\n",
    "    def get_ipix_tfds(M_tfds):\n",
    "        _res = gen_ipix_frame2d(0)\n",
    "        tfds = [gen_ipix_frame2d(i) for i in range(M_tfds)]\n",
    "        return tfds\n",
    "\n",
    "    assert config.N == c_tensor_total.shape[0]\n",
    "    assert not (config.SCNR_db_random_constant and config.SCNR_db_random_choice)\n",
    "    N = config.N\n",
    "    K = config.K\n",
    "\n",
    "    recon_vec_rng = torch.tensor(get_reconstruction_point_cloud_vec(config, param_ind=0), dtype=torch.float32)\n",
    "    recon_vec_vel = torch.tensor(get_reconstruction_point_cloud_vec(config, param_ind=1), dtype=torch.float32)\n",
    "\n",
    "    with_target = False\n",
    "    tfds0 = get_ipix_tfds(M0)\n",
    "    with_target = True\n",
    "    tfds1 = get_ipix_tfds(M1)\n",
    "\n",
    "    assert tfds1[0][0].shape == tfds0[0][0].shape and tfds1[0][1].shape == tfds0[0][1].shape\n",
    "    tfds = tfds1 + tfds0\n",
    "    tfds = [split_auxillary_structure(item) for item in tfds]\n",
    "\n",
    "    return tfds\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ipix data reader\n",
    "reads and preprocesses  the ipix data from the files. It extracts relevant parameters, truncates the data based on the provided configuration, computes the clutter velocity and generates the processed data tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data_ipix(config):\n",
    "    with open(config.ipix_pkl_path, 'rb') as handle:\n",
    "        ipix_data = pickle.load(handle)\n",
    "        PRI = ipix_data['PRI']\n",
    "        B = ipix_data['B']\n",
    "        rng_bins = ipix_data['rng_bins']\n",
    "        adc_data = ipix_data['adc_data']\n",
    "\n",
    "    rng_bins = rng_bins[:config.ipix_max_nrange_bins]\n",
    "    adc_data = adc_data[:config.ipix_max_nrange_bins, :]\n",
    "    if not config.ipix_file_range_bins:\n",
    "        assert config.N <= len(rng_bins) * 2\n",
    "        adc_data = adc_data[:config.N // 2, :]\n",
    "        rng_bins = rng_bins[:config.N // 2]\n",
    "    else:\n",
    "        config.N = len(rng_bins) * 2\n",
    "    assert config.N == len(rng_bins) * 2\n",
    "    config.T_PRI = PRI\n",
    "    config.B_chirp = B\n",
    "    if '19980205_191043' in config.ipix_pkl_path:\n",
    "        # cut weird zero part of this file\n",
    "        adc_data = adc_data[:, :50000]\n",
    "    # convert to fast-time x slow-time data\n",
    "    rng_bins = rng_bins - rng_bins[0]\n",
    "    config.r_0_max = rng_bins[-1]\n",
    "    clutter_omega_r = ((2 * np.pi) / config.N) * ((2 * B) / 3e8) * rng_bins\n",
    "    # workaround to prevent GPU overflow in multiple iterations\n",
    "    try:\n",
    "        clutter_range_steering_tensor = torch.exp(-1j * torch.tensor(torch.unsqueeze(torch.arange(config.N, dtype=torch.float32), -1) * torch.unsqueeze(clutter_omega_r, 0), dtype=torch.complex128))\n",
    "        c_tensor = clutter_range_steering_tensor @ adc_data\n",
    "    except:\n",
    "        clutter_range_steering_tensor = np.exp(-1j * torch.tensor(torch.unsqueeze(torch.arange(config.N, dtype=torch.float32), -1) * torch.unsqueeze(clutter_omega_r, 0), dtype=torch.complex128))\n",
    "        c_tensor = clutter_range_steering_tensor @ adc_data\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    estimate clutter Doppler frequency using welch method: \n",
    "        c_tensor[i] = e ^ {j 2 \\pi f_d kT_PRI}\n",
    "        f_d = (2 * f_c * clutter_vel) / c\n",
    "    \"\"\"\n",
    "\n",
    "    Pxx_den_list = []\n",
    "    for i in range(adc_data.shape[0]):\n",
    "        f, Pxx_den = scipy.signal.welch(adc_data[i], 1 / PRI, return_onesided=False)\n",
    "        Pxx_den_list.append(Pxx_den)\n",
    "\n",
    "    PSD = np.mean(np.array(Pxx_den_list), 0)\n",
    "    PSD = PSD / np.max(PSD)\n",
    "    clutter_fd = f[np.argmax(PSD)]\n",
    "    clutter_vel = -(3e8 * clutter_fd) / (2 * 9.39e9)\n",
    "\n",
    "    return c_tensor, rng_bins, clutter_vel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dataset\n",
    "This function generates the dataset. It loads and processes data from multiple files, splits it into train, validation, and test datasets, and applies the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_ipix(config, apply_tf_preprocess_pipe=True, split_data=True, return_dict=False):\n",
    "    if config.ipix_cv_mode:\n",
    "        # load train and validation\n",
    "        data_dict_per_file = {}\n",
    "        cdf_files_list = [f for f in os.listdir(config.ipix_pkl_path_dir) if not f.startswith('.')]\n",
    "        cdf_files_list = [x for x in cdf_files_list if x not in config.ipix_pkl_cv_hold_out]\n",
    "        for cdf_file in cdf_files_list:\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            # read raw data and convert to fast-time x slow-time complex data\n",
    "            c_tensor_total, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            config.r_0_max = rng_bins_ipix[-1]\n",
    "            M_valid = int(config.M_valid / len(cdf_files_list))\n",
    "            M0_valid = int(config.without_target_ratio_test * M_valid)\n",
    "            M1_valid = M_valid\n",
    "            M_train = int(config.M_train / len(cdf_files_list))\n",
    "            M0_train = int(config.without_target_ratio * M_train)\n",
    "            M1_train = M_train\n",
    "            # generate tf.data.Dataset objects\n",
    "            data = {}\n",
    "            c_tensor_total_valid = c_tensor_total[:, int(0.9 * c_tensor_total.shape[1]):]\n",
    "            data['valid'] = gen_ipix_pipeline_dataset(c_tensor_total_valid, clutter_vel, config, M0_valid, M1_valid)\n",
    "\n",
    "            c_tensor_total_train = c_tensor_total[:, :int(0.9 * c_tensor_total.shape[1])]\n",
    "            data['train'] = gen_ipix_pipeline_dataset(c_tensor_total_train, clutter_vel, config, M0_train, M1_train)\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                # add data pipeline functions (maps)\n",
    "                for set_type in ['train', 'valid']:\n",
    "                    data[set_type] = torch_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data\n",
    "\n",
    "        data = {}\n",
    "        for set_type in ['train', 'valid']:\n",
    "            data[set_type] = data_dict_per_file[cdf_files_list[0]][set_type]\n",
    "            for cdf_file in cdf_files_list[1:]:\n",
    "                data[set_type] = data[set_type].concatenate(data_dict_per_file[cdf_file][set_type])\n",
    "\n",
    "        # load test\n",
    "        data_dict_per_file = {}\n",
    "        for cdf_file in config.ipix_pkl_cv_hold_out:\n",
    "            assert cdf_file not in cdf_files_list\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            c_tensor_total_test, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            M_test = int(config.M_test / len(config.ipix_pkl_cv_hold_out))\n",
    "            M0_test = int(config.without_target_ratio_test * M_test)\n",
    "            M1_test = M_test\n",
    "            data['test'] = gen_ipix_pipeline_dataset(c_tensor_total_test, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                data['test'] = torch_dataset_pipeline(config, data['test'])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data['test']\n",
    "\n",
    "        data['test'] = data_dict_per_file[config.ipix_pkl_cv_hold_out[0]]\n",
    "        for cdf_file in config.ipix_pkl_cv_hold_out[1:]:\n",
    "            data['test'] = data['test'].concatenate(data_dict_per_file[cdf_file])\n",
    "    else:\n",
    "        data_dict_per_file = {}\n",
    "        cdf_files_list = [f for f in os.listdir(config.ipix_pkl_path_dir) if not f.startswith('.')]\n",
    "        assert len(cdf_files_list) > 0\n",
    "        for cdf_file in cdf_files_list:\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            c_tensor_total, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            config.r_0_max = rng_bins_ipix[-1]\n",
    "            M_test = int(config.M_test / len(cdf_files_list))\n",
    "            M0_test = int(config.without_target_ratio_test * M_test)\n",
    "            M1_test = M_test\n",
    "            M_valid = int(config.M_valid / len(cdf_files_list))\n",
    "            M0_valid = int(config.without_target_ratio_test * M_valid)\n",
    "            M1_valid = M_valid\n",
    "            M_train = int(config.M_train / len(cdf_files_list))\n",
    "            M0_train = int(config.without_target_ratio * M_train)\n",
    "            M1_train = M_train\n",
    "\n",
    "            data = {}\n",
    "            if split_data:\n",
    "                c_tensor_total_test = c_tensor_total[:, int(0.9 * c_tensor_total.shape[1]):]\n",
    "                data['test'] = gen_ipix_pipeline_dataset(c_tensor_total_test, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "                c_tensor_total_valid = c_tensor_total[:, int(0.85 * c_tensor_total.shape[1]): int(0.9 * c_tensor_total.shape[1])]\n",
    "                data['valid'] = gen_ipix_pipeline_dataset(c_tensor_total_valid, clutter_vel, config, M0_valid, M1_valid)\n",
    "\n",
    "                c_tensor_total_train = c_tensor_total[:, :int(0.85 * c_tensor_total.shape[1])]\n",
    "                data['train'] = gen_ipix_pipeline_dataset(c_tensor_total_train, clutter_vel, config, M0_train, M1_train)\n",
    "            else:\n",
    "                M1_test = config.M_test\n",
    "                M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "                data['test'] = gen_ipix_pipeline_dataset(c_tensor_total, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                for set_type in ['train', 'valid', 'test']:\n",
    "                    data[set_type] = torch_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data\n",
    "\n",
    "        if return_dict:\n",
    "            return data_dict_per_file\n",
    "        else:\n",
    "            data = {}\n",
    "            for set_type in ['train', 'valid', 'test']:\n",
    "                data[set_type] = data_dict_per_file[cdf_files_list[0]][set_type]\n",
    "                for cdf_file in cdf_files_list[1:]:\n",
    "                    data[set_type] = data[set_type].concatenate(data_dict_per_file[cdf_file][set_type])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data main func\n",
    "loads and preprocesses data based on the provided configuration, supports multiple data types, sets the model input and output dimensions, and optionally returns data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, use_make_iterators=True, apply_tf_preprocess_pipe=True):\n",
    "    model_input_dim_set = 'train'\n",
    "    if config.data_name == \"ipix\":\n",
    "        data = get_dataset_ipix(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "        model_input_dim_set = 'test'\n",
    "    elif config.data_name == \"compound_gaussian\":\n",
    "        data = get_dataset_compound_gaussian(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "        if config.compound_gaussian_add_wgn:\n",
    "            data_wgn = get_dataset_wgn(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "            for key in data.keys():\n",
    "                # rd_signal , label_tensor, (param_val_tensor, scnr_tensor, gamma_shape, clutter_vel, clutter_label_tensor)\n",
    "                data[key] = data[key].map(lambda x0, x1, x2: (x0, x1, (x2[0], x2[1], x2[2], torch.tensor(0.0), torch.tensor(0.0))))\n",
    "                data[key] = data[key].concatenate(data_wgn[key])\n",
    "    elif config.data_name == \"wgn\":\n",
    "        data = get_dataset_wgn(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "    else:\n",
    "        raise Exception(' ')\n",
    "\n",
    "    # set model_input_dim\n",
    "    config.model_input_dim = get_model_input_dim(data, model_input_dim_set)\n",
    "    config.model_output_dim = get_model_output_dim(data, model_input_dim_set)\n",
    "\n",
    "    if use_make_iterators:\n",
    "        # make data iterators (shuffle, batch, etc.)\n",
    "        data_iterators = make_iterators(data, config)\n",
    "        return config, data_iterators\n",
    "    else:\n",
    "        return config, data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = os.getcwd()\n",
    "config_path = '/home/leshkar/Desktop/BGU/configs/config.json'  \n",
    "args = get_args(config_path)\n",
    "config = read_config(args)\n",
    "gpu_init()\n",
    "set_logger_and_tracker(config)\n",
    "#save_scripts(config,SRC_DIR)\n",
    "print_config(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "config, data = load_data(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
