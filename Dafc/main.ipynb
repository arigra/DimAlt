{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Alternating Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before we begin, we need to download the IPIX data files. These files can be found here: http://soma.mcmaster.ca/ipix.php.*\n",
    "\n",
    "*In this address we find 12 .iso files, which we need to extract to get .cdf files.*\n",
    "\n",
    "*After we obtain these .cfd files, we need to save them in a folder: '.../datasets/IPIX/15m/cdf' so we can use it later.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import scipy\n",
    "import shutil\n",
    "import pickle\n",
    "import mlflow\n",
    "import logging\n",
    "import datetime\n",
    "import argparse\n",
    "import commentjson\n",
    "import numpy as np\n",
    "from bunch import Bunch\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from random import randint\n",
    "from collections import OrderedDict\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Dropout,  Activation, LeakyReLU, AveragePooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, Callback, EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .py imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dafc0 import *\n",
    "from Dafc1 import *\n",
    "from Dafc2 import *\n",
    "from Dafc3 import *\n",
    "from Dafc4 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dafc0 - convert .iso to .pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the .cdf files and turn them into workable .pkl files containing all the necessary data:\n",
    "    \n",
    "* adc_data (analog to digital converted data) - X: (varies: 27-34, 60000)\n",
    "* Pulse Repetition Interval - PRI: ()\n",
    "* Range bins (can be a 1D array or a list) - rng_bins: (varies: 27-34, )\n",
    "* Bandwidth - B: ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and dumped all pkl files!\n"
     ]
    }
   ],
   "source": [
    "pol = 'hh'\n",
    "cdf_dir = '/Users/arigra/Desktop/DL projects/Dafc/datasets/IPIX/15m/cdf'\n",
    "pkl_dir = '/Users/arigra/Desktop/DL projects/Dafc/datasets/IPIX/15m/pkl1/' + pol\n",
    "cdf_path_list = [f for f in os.listdir(cdf_dir) if not f.startswith('.')]\n",
    "\n",
    "for cdf_path in cdf_path_list:\n",
    "\n",
    "    cdf_path = os.path.join(cdf_dir, cdf_path)\n",
    "    X, PRI, rng_bins, B = parse_ipix_data(cdf_path, pol=pol, adc_like_I=2, adc_like_Q=3, adc_cross_I=0, adc_cross_Q=1)\n",
    "    # dump to pkl_file\n",
    "    dir_name = pkl_dir\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    pkl_file_name = os.path.basename(cdf_path).replace(\".CDF\",\"\") + \"_pol_\" + pol + \".pkl\"\n",
    "\n",
    "    pickle.dump({\"PRI\": PRI, \"rng_bins\": rng_bins, \"B\": B,\"adc_data\": X}, open(os.path.join(dir_name, pkl_file_name), 'wb'), protocol=3)\n",
    "print(\"Successfully created and dumped all pkl files!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dafc1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the config file, which determines the specific values and decisions in the code.\n",
    "\n",
    "We also define the loggings and initialize the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded config file!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SRC_DIR = os.getcwd()\n",
    "config_path = '/Users/arigra/Desktop/DL projects/Dafc/config.json'  \n",
    "args = get_args(config_path)\n",
    "config = read_config(args)\n",
    "gpu_init()\n",
    "set_logger_and_tracker(config)\n",
    "print(\"Successfully loaded config file!\")\n",
    "# To watch the properties of the config object, uncomment the following lines:\n",
    "#print_config(config)\n",
    "#config_properties = list(config)\n",
    "#config_properties.sort()\n",
    "#for attr_name in config_properties:\n",
    "#    attr_value = config[attr_name]\n",
    "#    print(f'{attr_name}: {attr_value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dafc2 - Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most complicated part of the code, we will now try to give an explanation as simple as possible, by taking this particular flow.\n",
    "\n",
    "1. <span style=\"color: purple;\"> **load_data:** We start this with \"load_data\" which is the main function in this part.</span>\n",
    "\n",
    "    <span style=\"color: purple;\">In our case,config.data_name = \"ipix\", therefore \"load_data\" chooses to use the \"get_dataset_ipix\" function.</span>\n",
    "\n",
    "    2. <span style=\"color: green;\">**get_dataset_ipix:** This function operates in 2 different ways, given that config.ipix_cv_mode = False, this is the process:</span>\n",
    "\n",
    "        <span style=\"color: green;\">We first initialize \"data_dict_per_file\" so we can store the processed data there, then we now call the \"read_ipix_data\" function for each file.</span>\n",
    "\n",
    "        3. <span style=\"color: orange;\">**read_data_ipix:** Here we finally start using the data:</span>\n",
    "            * <span style=\"color: orange;\">We assign the data from the pkl files to variables (example: PRI = ipix_data['PRI'])</span>\n",
    "            * <span style=\"color: orange;\">Using these variables, we create the c_tensor (the signal after range steering), clutter velocity, and range bins.</span>\n",
    "            * <span style=\"color: orange;\">c_tensor:\n",
    "\n",
    "            $$ \\text{omegaClutter} = \\frac{2\\pi B}{3e8} $$\n",
    "            $$ \\text{clutterRangeSteeringTensor}[i,j] = e^{(-1j \\cdot i \\cdot \\text{omegaClutter}[j])}$$ \n",
    "            $$ \\text{cTensor} = clutterRangeSteeringTensor \\times adcData $$\n",
    "\n",
    "            * <span style=\"color: orange;\">clutter velocity: we apply the welch method for each range bin. From that, we create the PSD (Power Spectral Density), and by using a simple calculation, we obtain the clutter velocity.</span>\n",
    "            * <span style=\"color: orange;\">range bins: we set the number of range bins to be the minimum of all samples.</span>\n",
    "            \n",
    "            <span style=\"color: blue;\">*finally we obtain the c_tensor with shape (54, 60000), rng_bins with shape (27,), and clutter velocity which is a float64*</span>\n",
    "\n",
    "        <span style=\"color: green;\"> after we have the c_tensor, clutter velocity and the range bins we define different Ms, which define how many samples of the data we are going to use (for train, validation and test).</span>\n",
    "        \n",
    "        <span style=\"color: green;\">Now we want to define the train, validation and test sets, in order to do so, we use the \"gen_ipix_pipeline_dataset\" function.</span>\n",
    "        \n",
    "        4. <span style=\"color: orange;\">**gen_ipix_pipeline_dataset:** \n",
    "        \n",
    "            <span style=\"color: orange;\">This function processes the ipix dataframes, applies random Doppler shifts, generates radar signals and labels for target detection and returns a dataset consisting of frames with and without targets.</span>\n",
    "\n",
    "\n",
    "            5. <span style=\"color: red;\"> **get_reconstruction_point_cloud_vec:** </span>\n",
    "            \n",
    "                <span style=\"color: red;\">calculates and returns vectors used for point cloud reconstruction in the ipix pipeline.\n",
    "                the function first checks if we use FFT dimensions for point cloud reconstruction, If this option is enabled, it rescales the dimensions(in our case it is enabled). This rescaling is done to achieve higher resolution in the reconstructed point cloud.</span>\n",
    "\n",
    "                <span style=\"color: red;\">The function then calls the get_fft_resolutions function to calculate the resolution and values for the range, velocity, and azimuth dimensions of the point cloud.</span>\n",
    "\n",
    "                <span style=\"color: red;\">If param_ind is 0, it returns the range bins values, which represent the distances from the radar sensor to the objects in the range dimension. If param_ind is 1, it returns the velocity bins values, representing the velocities of the objects.</span>\n",
    "            \n",
    "            <span style=\"color: blue;\">finally, we are left with recon_vec_rng (27,) and recon_vec_vel (63,)</span>\n",
    "            \n",
    "            <span style=\"color: orange;\">now, after we obtaind the recon vectors, we get tfds0 and tfds1 with the get_ipix_tfds function, which maps the in the following way:</span>\n",
    "\n",
    "            6. <span style=\"color: red;\">**gen_ipix_frame2d**</span>\n",
    "\n",
    "                <span style=\"color: red;\">This function generates a single frame of the ipix pipeline in the following way:</span>\n",
    "\n",
    "                 * <span style=\"color: blue;\">randomly cropping the c_tensor, making it a tensor of size (54,64)</span>\n",
    "                 * <span style=\"color: red;\">performing doppler shifts</span>\n",
    "                 * <span style=\"color: red;\">for targetless (tfds0), fills zeros and -1000.0 values to indicate no target</span>\n",
    "                 * <span style=\"color: red;\">for tfds1, using the \"gen_target_matrix\" function to generate the needed data </span>\n",
    "                    \n",
    "                          \n",
    "\n",
    "                7. <span style=\"color: yellow;\">**get_target_matrix:**</span>\n",
    "\n",
    "                    <span style=\"color: yellow;\">Generates a target matrix along with corresponding labels, parameter values,and SCNR value.</span>\n",
    "                \n",
    "                <span style=\"color: red;\">The output of this function is:</span>\n",
    "\n",
    "                <span style=\"color: blue;\">rd_signal + c_tensor (54,64), label_tensor (27,63), param_val_tensor(None,), scnr_tensor(None,), tf.constant(0.0), clutter_vel_local(), tf.constant(0.0)</span>\n",
    "\n",
    "                <span style=\"color: red;\">so, tfds = return rd_signal + c_tensor, label_tensor, param_val_tensor, scnr_tensor, tf.constant(0.0), clutter_vel_local, tf.constant(0.0)</span>\n",
    "\n",
    "                <span style=\"color: red;\">We now concatenate the tfds with (tfds1) and without targets (tfds0), and use the split_auxillary_structure to map them, the tfds size loops between 555, 55 and 740 for train, test and validation</span>\n",
    "\n",
    "        <span style=\"color: green;\">We are now finally back to get_dataset_ipix. Testing the properties of the train, validation and test we get a dictionary of 740 train set _mapDataset, 555 test set _mapDataset, and 55 validation set _mapDataset</span>\n",
    "\n",
    "        <span style=\"color: green;\">Now, on each one we apply a tensorFlow preprocess using the function:</span>\n",
    "\n",
    "        8. <span style=\"color: orange;\">**\"tf_dataset_pipeline:\"**</span> \n",
    "\n",
    "            * <span style=\"color: orange;\">transpose the data, swapping real and imaginary parts of each element.</span> \n",
    "            * <span style=\"color: orange;\">center by subtracting the mean from the last axis and reshape to original shape.</span> \n",
    "            * <span style=\"color: orange;\">standartization by element-wise division.</span> \n",
    "            * <span style=\"color: orange;\">concat the real and imaginary parts of the matrix along the last axis</span> \n",
    "            * <span style=\"color: orange;\">processing the labels.</span> \n",
    "        \n",
    "        <span style=\"color: green;\">Which gives us the data processed as we need.</span>\n",
    "\n",
    "    <span style=\"color: purple;\">We now finally activate the functions \"get_model_input_dim\" and \"get_model_output_dim\" to get the input and output dimensions.</span>\n",
    "\n",
    "    <span style=\"color: purple;\">We also use the \"make_iterators\" function to prepare iterators for this dataset, which can be used for efficient batch processing.</span>\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_iterators(): M_train: 19988\n",
      "Successfully loaded data!\n"
     ]
    }
   ],
   "source": [
    "config, data = load_data(config)\n",
    "print(\"Successfully loaded data!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dafc3 - Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build the model, Using the settings in the config file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TwoStageFcModel\"\n",
      "____________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                  Output Shape                                            Param #              \n",
      "============================================================================================================================================\n",
      " input (InputLayer)                                            [(None, 54, 128)]                                       0                    \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer (TwoStageFcLayer)                          (None, 128, 1024)                                       139136               \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer_1 (TwoStageFcLayer)                        (None, 16, 256)                                         264464               \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer_2 (TwoStageFcLayer)                        (None, 4, 128)                                          32964                \n",
      "                                                                                                                                            \n",
      " flatten (Flatten)                                             (None, 512)                                             0                    \n",
      "                                                                                                                                            \n",
      " dense_6 (Dense)                                               (None, 63)                                              32319                \n",
      "                                                                                                                                            \n",
      " activation_6 (Activation)                                     (None, 63)                                              0                    \n",
      "                                                                                                                                            \n",
      "============================================================================================================================================\n",
      "Total params: 468883 (1.79 MB)\n",
      "Trainable params: 468883 (1.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "____________________________________________________________________________________________________________________________________________\n",
      "Failed to plot model:name 'plot_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dafc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m build_trainer(model, data, config)\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Desktop/DL projects/Dafc/Dafc4.py:284\u001b[0m, in \u001b[0;36mClassificationTrainerKeras.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     data_train \u001b[39m=\u001b[39m data_train\u001b[39m.\u001b[39mmap(compound_gaussian_split_aux_trainer)\n\u001b[1;32m    282\u001b[0m     data_valid \u001b[39m=\u001b[39m data_valid\u001b[39m.\u001b[39mmap(compound_gaussian_split_aux_trainer)\n\u001b[0;32m--> 284\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_train\u001b[39m.\u001b[39;49mfit(data_train, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_epochs, validation_data\u001b[39m=\u001b[39;49mdata_valid, callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_list, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mfit_verbose)\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = build_trainer(model, data, config)\n",
    "history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
