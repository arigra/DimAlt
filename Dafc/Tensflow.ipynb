{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bilik bom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import commentjson\n",
    "from random import randint\n",
    "from bunch import Bunch\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, Callback, EarlyStopping\n",
    "logger = logging.getLogger(\"logger\")\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Input\n",
    "from tensorflow.keras.layers import Dropout,  Activation, LeakyReLU, AveragePooling1D\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config functions "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Config class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_VERBOSE_WAIVER = ['save_model', 'tracking_uri', 'quiet', 'sim_dir', 'train_writer', 'test_writer', 'valid_writer']\n",
    "class Config(Bunch):\n",
    "    \"\"\" class for handling dicrionary as class attributes \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Config, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def print(self):\n",
    "        line_len = 122\n",
    "        line = \"-\" * line_len\n",
    "        logger.info(line + \"\\n\" +\n",
    "              \"| {:^35s} | {:^80} |\\n\".format('Feature', 'Value') +\n",
    "              \"=\" * line_len)\n",
    "        for key, val in sorted(self.items(), key= lambda x: x[0]):\n",
    "            if isinstance(val, OrderedDict):\n",
    "                raise NotImplementedError(\"Nested configs are not implemented\")\n",
    "            else:\n",
    "                if key not in CONFIG_VERBOSE_WAIVER:\n",
    "                    logger.info(\"| {:35s} | {:80} |\\n\".format(key, str(val)) + line)\n",
    "        logger.info(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(argv):\n",
    "    argparser = argparse.ArgumentParser(description=__doc__)\n",
    "    argparser.add_argument('--config', default=None, type=str, help='path to config file')\n",
    "    argparser.add_argument('--seed', default=None, type=int, help='randomization seed')\n",
    "    argparser.add_argument('--exp_name', default=None, type=int, help='Experiment name')\n",
    "    argparser.add_argument('--num_targets', default=None, type=int, help='Number of simulated targets')\n",
    "    argparser.set_defaults(quiet=False)\n",
    "    args, unknown = argparser.parse_known_args(argv)\n",
    "    #args = argparser.parse_args()\n",
    "\n",
    "    return args\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_to_dict(fname):\n",
    "    \"\"\" read json config file into ordered-dict \"\"\"\n",
    "    fname = Path(fname)\n",
    "    with fname.open('rt') as handle:\n",
    "        config_dict = commentjson.load(handle, object_hook=OrderedDict)\n",
    "        return config_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(args):\n",
    "    \"\"\" read config from json file and update by the command line arguments \"\"\"\n",
    "    if args.config is not None:\n",
    "        json_file = args.config\n",
    "    else:\n",
    "        json_file = \"/Users/arigra/Desktop/DL projects/Dafc/config.json\"  # Replace with your default config file path\n",
    "\n",
    "    config_dict = read_json_to_dict(json_file)\n",
    "    config = Config(config_dict)\n",
    "\n",
    "    for arg in sorted(vars(args)):\n",
    "        key = arg\n",
    "        val = getattr(args, arg)\n",
    "        if val is not None:\n",
    "            setattr(config, key, val)\n",
    "\n",
    "    if args.seed is None and config.seed is None:\n",
    "        \n",
    "        MAX_SEED = sys.maxsize\n",
    "        config.seed = randint(0, MAX_SEED)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_init():\n",
    "    \"\"\" Allows GPU memory growth \"\"\"\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    logger.info(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            logger.info(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            logger.info(\"MESSAGE\", e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger and tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_logger_and_tracker(config):\n",
    "    ''' configure the mlflow tracker:\n",
    "        1. set tracking location (uri)\n",
    "        2. configure exp name/id\n",
    "        3. define parameters to be documented\n",
    "    '''\n",
    "\n",
    "    config.exp_name_time = \"{}_{}_{}\".format(config.exp_name,datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"),config.seed)\n",
    "    config.tensor_board_dir = os.path.join('..',\n",
    "                                           'results',\n",
    "                                           config.exp_name,\n",
    "                                           config.exp_name_time)\n",
    "\n",
    "    if not os.path.exists(config.tensor_board_dir):\n",
    "        os.makedirs(config.tensor_board_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scripts(config,SRC_DIR):\n",
    "    path = os.path.join(config.tensor_board_dir, 'scripts')\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    scripts_to_save = glob.glob('{}/**/*.py'.format(SRC_DIR), recursive=True) + [config.config]\n",
    "    scripts_to_save = [script for script in scripts_to_save if '{}/results'.format(SRC_DIR) not in script]\n",
    "    if scripts_to_save is not None:\n",
    "        for script in scripts_to_save:\n",
    "            dst_file = os.path.join(path, os.path.basename(script))\n",
    "            try:\n",
    "                shutil.copyfile(os.path.join(os.path.dirname(sys.argv[0]), script), dst_file)\n",
    "            except:\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_config(config):\n",
    "    print('')\n",
    "    print('#' * 70)\n",
    "    print('Configurations at beginning of run')\n",
    "    print('#' * 70)\n",
    "    for key in config.keys():\n",
    "        print('{}, {}'.format(key,config['{}'.format(key)]))\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "Configurations at beginning of run\n",
      "######################################################################\n",
      "model_input_dim, [None]\n",
      "model_output_dim, 1\n",
      "quiet, False\n",
      "seed, 3775404699870012136\n",
      "exp_name, temp\n",
      "load_complete_model, False\n",
      "load_model_path, \n",
      "con_inf_rng_path, \n",
      "con_inf_vel_path, \n",
      "eval_model_pth, \n",
      "detection_pfa_miss_M_valid, 5000\n",
      "detection_exp_type, pd\n",
      "ipix_pkl_path, \n",
      "ipix_pkl_path_dir, /Users/arigra/Desktop/DL projects/Dafc/datasets/IPIX/15m/pkl/hh\n",
      "ipix_pkl_cv_hold_out, \n",
      "ipix_cdf_files_list, []\n",
      "ipix_skip_cv_iters, []\n",
      "ipix_predefined_cv_iters, []\n",
      "ipix_cv_mode, False\n",
      "ipix_cv_script, main_train\n",
      "ipix_cv_rng_pth, ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng_2022-03-12_17-29-13_405075\n",
      "ipix_cv_vel_pth, ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel_2022-03-12_09-02-17_826518\n",
      "sweep_run_eval_con_inf, False\n",
      "sweep_run_eval, True\n",
      "sweep_dict, OrderedDict([('mc_iteration', True), ('num_targets', False), ('learning_rate', False), ('activation', False), ('batch_size', False), ('l2_reg_parameter', False), ('dense_sizes', False), ('two_stage_fc_dims', False), ('two_stage_fc_dense_sizes', False), ('two_stage_fc_use_batch_norm', False), ('two_stage_fc_dropout_rate', False), ('CBBCE_predefined_weight', False), ('point_cloud_reconstruction_CBBCE_gaussian_smoothing_std', False), ('point_cloud_reconstruction_dim', False), ('use_lr_scheduler', False), ('use_lr_scheduler_deriv', False), ('cfar_window_size', False), ('beamforming_method', False), ('cfar_os_order_statistic', False), ('cfar_num_censor_cells_largest', False), ('augment_list', False), ('dummy_config', False), ('mvdr_loading_factor', False)])\n",
      "mc_iteration_sweep_list, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "num_targets_sweep_list, [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "learning_rate_sweep_list, [0.01, 0.001]\n",
      "scale_sweep_list, [0.5, 1, 2]\n",
      "data_merge_size_sweep_list, [0.25, 0.5, 0.75]\n",
      "l2_reg_parameter_sweep_list, [0.1, 0.01, 0.001, 0.0001, 1e-05]\n",
      "activation_sweep_list, ['relu', 'tanh']\n",
      "beamforming_method_sweep_list, ['MVDR', 'MUSIC', 'MLE']\n",
      "batch_size_sweep_list, [32, 64, 128, 256, 512]\n",
      "dense_sizes_sweep_list, [[2048, 1024, 512], [256, 512, 1024, 512], [2048, 1024, 512, 256], [256, 1024, 4096, 512], [256, 2048, 1024, 512], [256, 512, 2048, 1024, 256, 64], [512, 2048, 256, 32], [256, 1024, 128, 32]]\n",
      "nnmvdr_fc_encoder_dim_sweep_list, [128, 64, 16, 8, 4]\n",
      "two_stage_fc_use_batch_norm_sweep_list, [[False, False, False], [True, True, True], [True, False, True], [False, True, False]]\n",
      "two_stage_fc_dropout_rate_sweep_list, [[0.0, 0.0, 0.0], [0.0, 0.25, 0.0], [0.0, 0.5, 0.0], [0.25, 0.0, 0.25], [0.5, 0.5, 0.5]]\n",
      "two_stage_fc_dims_sweep_list, [[[32, 128], [128, 1024], [256, 2048], [64, 512], [16, 256]], [[32, 64], [128, 512], [64, 256], [8, 128]], [[64, 128], [128, 512], [32, 256], [16, 128]], [[128, 1024], [16, 256], [8, 128], [2, 32]], [[128, 1024], [16, 256], [4, 128]]]\n",
      "two_stage_fc_dense_sizes_sweep_list, [[128, 32], [512, 256, 128], [1024, 256], [512, 64]]\n",
      "point_cloud_reconstruction_dim_sweep_list, [32, 64, 128, 256]\n",
      "use_lr_scheduler_sweep_list, [True, False]\n",
      "use_lr_scheduler_deriv_sweep_list, [True, False]\n",
      "cfar_window_size_sweep_list, [[0.2, 0.2, 0.2], [0.15, 0.15, 0.15], [0.1, 0.1, 0.1], [0.05, 0.05, 0.05]]\n",
      "cfar_os_order_statistic_sweep_list, [0.25, 0.5, 0.75]\n",
      "cfar_num_censor_cells_largest_sweep_list, [0.1, 0.25, 0.5, 0.75]\n",
      "mvdr_loading_factor_sweep_list, [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 10.0, 15.0]\n",
      "dummy_config_sweep_list, ['']\n",
      "data_name, ipix\n",
      "ipix_max_nrange_bins, 27\n",
      "ipix_file_range_bins, True\n",
      "ipix_random_shift_doppler, True\n",
      "random_num_targets, True\n",
      "num_targets, 8\n",
      "M_train, 10000\n",
      "M_valid, 1000\n",
      "M_test, 10000\n",
      "without_target_ratio, 1.0\n",
      "without_target_ratio_test, 0.5\n",
      "N, 64\n",
      "K, 64\n",
      "L, 10\n",
      "FOV, 60\n",
      "SCNR_db, -5\n",
      "B_chirp, 50000000.0\n",
      "f_s, 1000000.0\n",
      "T_idle, 5e-05\n",
      "compound_gaussian_add_wgn, False\n",
      "compound_gaussian_dims, 2\n",
      "compound_gaussian_single_clutter_vel, True\n",
      "compound_gaussian_constant_clutter_vel, None\n",
      "random_SCNR, True\n",
      "SCNR_db_range, [-5, 10]\n",
      "SCNR_db_random_choice, False\n",
      "SCNR_db_random_constant, False\n",
      "SCNRs_eval, [-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10]\n",
      "compound_gaussian_gamma_shapes_eval, [0.5]\n",
      "sigma_f, 0.05\n",
      "compound_gaussian_random_gamma_shape, True\n",
      "gamma_shape_range, [0.1, 1.5]\n",
      "gamma_shape, 0.25\n",
      "T_PRI, 0.001\n",
      "CNR_db, 15\n",
      "signal_random_phase, True\n",
      "signal_physical_phase, True\n",
      "embedded_target, False\n",
      "embedded_target_vel_offset, 1.0\n",
      "embedded_target_azm_offset, 10.0\n",
      "v_r_min, -7.5\n",
      "v_r_max, 7.5\n",
      "v_0_min, -7.5\n",
      "v_0_max, 7.5\n",
      "r_0_min, 0\n",
      "r_0_max, 465\n",
      "f_c, 9390000000.0\n",
      "cfar_method, ca\n",
      "cfar_num_censor_cells_largest, 0.25\n",
      "cfar_num_censor_cells_smallest, 0.25\n",
      "cfar_os_order_statistic, 0.5\n",
      "cfar_single_param, []\n",
      "cfar_guard_cell, [0.1, 0.1, 0.1]\n",
      "cfar_window_size, [0.1, 0.1, 0.1]\n",
      "fit_verbose, 2\n",
      "num_epochs, 300\n",
      "batch_size, 256\n",
      "optimizer, adam\n",
      "learning_rate, 0.001\n",
      "l2_reg_parameter, 0.0001\n",
      "activation, tanh\n",
      "leaky_alpha, 0.1\n",
      "stop_max_acc, False\n",
      "use_model_checkpoint_best, False\n",
      "model_checkpoint_best_metric, val_mse\n",
      "model_checkpoint_epoch_period, 5\n",
      "save_fit_history, True\n",
      "use_early_stop, True\n",
      "early_stop_metric, val_loss\n",
      "early_stop_patience, 0.3333\n",
      "early_stop_mode, min\n",
      "use_lr_scheduler, False\n",
      "lr_scheduler_decay, 0.905\n",
      "lr_scheduler_period, 5\n",
      "lr_scheduler_epoch_threshold, 0.4\n",
      "use_lr_scheduler_plateau, True\n",
      "lr_scheduler_plateau_decay, 0.905\n",
      "lr_scheduler_plateau_window, 10\n",
      "lr_scheduler_plateau_cooldown, 5\n",
      "lr_scheduler_plateau_epoch_threshold, 0.05\n",
      "use_lr_scheduler_deriv, False\n",
      "lr_deriv_decay, 0.905\n",
      "lr_deriv_min_delta, -0.0001\n",
      "lr_deriv_period, 4\n",
      "lr_deriv_epoch_threshold, 0.3\n",
      "save_final_model, True\n",
      "use_CBBCE, True\n",
      "CBBCE_penalize_interference, False\n",
      "CBBCE_use_penalize_margin, False\n",
      "CBBCE_use_penalize_snr, False\n",
      "CBBCE_penalize_snr_use_geom_space, False\n",
      "CBBCE_penalize_margin, 5\n",
      "CBBCE_predefined_weight, 0\n",
      "two_stage_fc_stdize, True\n",
      "estimation_params, ['vel']\n",
      "point_cloud_reconstruction_dim, 64\n",
      "point_cloud_reconstruction, True\n",
      "point_cloud_reconstruction_3d, False\n",
      "point_cloud_reconstruction_2d, False\n",
      "point_cloud_reconstruction_fft_dims, True\n",
      "point_cloud_reconstruction_fft_dim_factor, 1\n",
      "point_cloud_reconstruction_3d_margins, [3.0, 0.2496006389776358, 9.594]\n",
      "point_cloud_reconstruction_bin_guard_margin, [1, 1, 0]\n",
      "point_cloud_reconstruction_pFA_values, [1e-05, 5e-05, 0.0001, 0.0005, 0.001]\n",
      "con_inf_use_model_only, False\n",
      "con_inf_use_projection_only, False\n",
      "evaluation_sets, ['test']\n",
      "augment_prob, 0.5\n",
      "augment_list, []\n",
      "additive_noise_std, 1.0\n",
      "row_shift, 32\n",
      "col_shift, 32\n",
      "trainer_name, detection_classification\n",
      "mode, Detection\n",
      "model_name, Detection-TwoStage-FC\n",
      "dense_sizes, [2048, 1024, 512]\n",
      "dense_dropout, None\n",
      "fc_batchnorm, False\n",
      "two_stage_fc_dims, [[128, 1024], [16, 256], [4, 128]]\n",
      "two_stage_fc_use_batch_norm, [False, False, False, False, False, False, False, False, False, False]\n",
      "two_stage_fc_dropout_rate, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "two_stage_fc_dense_sizes, []\n",
      "two_stage_fc_dense_dropout, []\n",
      "two_stage_fc_dense_batchnorm, None\n",
      "two_stage_fc_use_gap, False\n",
      "dummy_config, \n",
      "mc_iteration, 0\n",
      "exp_name_time, temp_2023-07-11_14-46-44_3775404699870012136\n",
      "tensor_board_dir, ../results/temp/temp_2023-07-11_14-46-44_3775404699870012136\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SRC_DIR = os.getcwd()\n",
    "config_path = '/Users/arigra/Desktop/DL projects/Dafc/config.json'  \n",
    "args = get_args(config_path)\n",
    "config = read_config(args)\n",
    "gpu_init()\n",
    "set_logger_and_tracker(config)\n",
    "#save_scripts(config,SRC_DIR)\n",
    "print_config(config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### config properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_chirp: 50000000.0\n",
      "CBBCE_penalize_interference: False\n",
      "CBBCE_penalize_margin: 5\n",
      "CBBCE_penalize_snr_use_geom_space: False\n",
      "CBBCE_predefined_weight: 0\n",
      "CBBCE_use_penalize_margin: False\n",
      "CBBCE_use_penalize_snr: False\n",
      "CNR_db: 15\n",
      "FOV: 60\n",
      "K: 64\n",
      "L: 10\n",
      "M_test: 10000\n",
      "M_train: 10000\n",
      "M_valid: 1000\n",
      "N: 64\n",
      "SCNR_db: -5\n",
      "SCNR_db_random_choice: False\n",
      "SCNR_db_random_constant: False\n",
      "SCNR_db_range: [-5, 10]\n",
      "SCNRs_eval: [-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10]\n",
      "T_PRI: 0.001\n",
      "T_idle: 5e-05\n",
      "activation: tanh\n",
      "activation_sweep_list: ['relu', 'tanh']\n",
      "additive_noise_std: 1.0\n",
      "augment_list: []\n",
      "augment_prob: 0.5\n",
      "batch_size: 256\n",
      "batch_size_sweep_list: [32, 64, 128, 256, 512]\n",
      "beamforming_method_sweep_list: ['MVDR', 'MUSIC', 'MLE']\n",
      "cfar_guard_cell: [0.1, 0.1, 0.1]\n",
      "cfar_method: ca\n",
      "cfar_num_censor_cells_largest: 0.25\n",
      "cfar_num_censor_cells_largest_sweep_list: [0.1, 0.25, 0.5, 0.75]\n",
      "cfar_num_censor_cells_smallest: 0.25\n",
      "cfar_os_order_statistic: 0.5\n",
      "cfar_os_order_statistic_sweep_list: [0.25, 0.5, 0.75]\n",
      "cfar_single_param: []\n",
      "cfar_window_size: [0.1, 0.1, 0.1]\n",
      "cfar_window_size_sweep_list: [[0.2, 0.2, 0.2], [0.15, 0.15, 0.15], [0.1, 0.1, 0.1], [0.05, 0.05, 0.05]]\n",
      "col_shift: 32\n",
      "compound_gaussian_add_wgn: False\n",
      "compound_gaussian_constant_clutter_vel: None\n",
      "compound_gaussian_dims: 2\n",
      "compound_gaussian_gamma_shapes_eval: [0.5]\n",
      "compound_gaussian_random_gamma_shape: True\n",
      "compound_gaussian_single_clutter_vel: True\n",
      "con_inf_rng_path: \n",
      "con_inf_use_model_only: False\n",
      "con_inf_use_projection_only: False\n",
      "con_inf_vel_path: \n",
      "data_merge_size_sweep_list: [0.25, 0.5, 0.75]\n",
      "data_name: ipix\n",
      "dense_dropout: None\n",
      "dense_sizes: [2048, 1024, 512]\n",
      "dense_sizes_sweep_list: [[2048, 1024, 512], [256, 512, 1024, 512], [2048, 1024, 512, 256], [256, 1024, 4096, 512], [256, 2048, 1024, 512], [256, 512, 2048, 1024, 256, 64], [512, 2048, 256, 32], [256, 1024, 128, 32]]\n",
      "detection_exp_type: pd\n",
      "detection_pfa_miss_M_valid: 5000\n",
      "dummy_config: \n",
      "dummy_config_sweep_list: ['']\n",
      "early_stop_metric: val_loss\n",
      "early_stop_mode: min\n",
      "early_stop_patience: 0.3333\n",
      "embedded_target: False\n",
      "embedded_target_azm_offset: 10.0\n",
      "embedded_target_vel_offset: 1.0\n",
      "estimation_params: ['vel']\n",
      "eval_model_pth: \n",
      "evaluation_sets: ['test']\n",
      "exp_name: temp\n",
      "exp_name_time: temp_2023-07-11_14-46-44_3775404699870012136\n",
      "f_c: 9390000000.0\n",
      "f_s: 1000000.0\n",
      "fc_batchnorm: False\n",
      "fit_verbose: 2\n",
      "gamma_shape: 0.25\n",
      "gamma_shape_range: [0.1, 1.5]\n",
      "ipix_cdf_files_list: []\n",
      "ipix_cv_mode: False\n",
      "ipix_cv_rng_pth: ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng/IPIX_3m_HH_K64_8targets_CV_twostage_fc_rng_2022-03-12_17-29-13_405075\n",
      "ipix_cv_script: main_train\n",
      "ipix_cv_vel_pth: ../results/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel/IPIX_3m_HH_K64_8targets_CV_twostage_fc_vel_2022-03-12_09-02-17_826518\n",
      "ipix_file_range_bins: True\n",
      "ipix_max_nrange_bins: 27\n",
      "ipix_pkl_cv_hold_out: \n",
      "ipix_pkl_path: \n",
      "ipix_pkl_path_dir: /Users/arigra/Desktop/DL projects/Dafc/datasets/IPIX/15m/pkl/hh\n",
      "ipix_predefined_cv_iters: []\n",
      "ipix_random_shift_doppler: True\n",
      "ipix_skip_cv_iters: []\n",
      "l2_reg_parameter: 0.0001\n",
      "l2_reg_parameter_sweep_list: [0.1, 0.01, 0.001, 0.0001, 1e-05]\n",
      "leaky_alpha: 0.1\n",
      "learning_rate: 0.001\n",
      "learning_rate_sweep_list: [0.01, 0.001]\n",
      "load_complete_model: False\n",
      "load_model_path: \n",
      "lr_deriv_decay: 0.905\n",
      "lr_deriv_epoch_threshold: 0.3\n",
      "lr_deriv_min_delta: -0.0001\n",
      "lr_deriv_period: 4\n",
      "lr_scheduler_decay: 0.905\n",
      "lr_scheduler_epoch_threshold: 0.4\n",
      "lr_scheduler_period: 5\n",
      "lr_scheduler_plateau_cooldown: 5\n",
      "lr_scheduler_plateau_decay: 0.905\n",
      "lr_scheduler_plateau_epoch_threshold: 0.05\n",
      "lr_scheduler_plateau_window: 10\n",
      "mc_iteration: 0\n",
      "mc_iteration_sweep_list: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "mode: Detection\n",
      "model_checkpoint_best_metric: val_mse\n",
      "model_checkpoint_epoch_period: 5\n",
      "model_input_dim: [None]\n",
      "model_name: Detection-TwoStage-FC\n",
      "model_output_dim: 1\n",
      "mvdr_loading_factor_sweep_list: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 10.0, 15.0]\n",
      "nnmvdr_fc_encoder_dim_sweep_list: [128, 64, 16, 8, 4]\n",
      "num_epochs: 300\n",
      "num_targets: 8\n",
      "num_targets_sweep_list: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "optimizer: adam\n",
      "point_cloud_reconstruction: True\n",
      "point_cloud_reconstruction_2d: False\n",
      "point_cloud_reconstruction_3d: False\n",
      "point_cloud_reconstruction_3d_margins: [3.0, 0.2496006389776358, 9.594]\n",
      "point_cloud_reconstruction_bin_guard_margin: [1, 1, 0]\n",
      "point_cloud_reconstruction_dim: 64\n",
      "point_cloud_reconstruction_dim_sweep_list: [32, 64, 128, 256]\n",
      "point_cloud_reconstruction_fft_dim_factor: 1\n",
      "point_cloud_reconstruction_fft_dims: True\n",
      "point_cloud_reconstruction_pFA_values: [1e-05, 5e-05, 0.0001, 0.0005, 0.001]\n",
      "quiet: False\n",
      "r_0_max: 465\n",
      "r_0_min: 0\n",
      "random_SCNR: True\n",
      "random_num_targets: True\n",
      "row_shift: 32\n",
      "save_final_model: True\n",
      "save_fit_history: True\n",
      "scale_sweep_list: [0.5, 1, 2]\n",
      "seed: 3775404699870012136\n",
      "sigma_f: 0.05\n",
      "signal_physical_phase: True\n",
      "signal_random_phase: True\n",
      "stop_max_acc: False\n",
      "sweep_dict: OrderedDict([('mc_iteration', True), ('num_targets', False), ('learning_rate', False), ('activation', False), ('batch_size', False), ('l2_reg_parameter', False), ('dense_sizes', False), ('two_stage_fc_dims', False), ('two_stage_fc_dense_sizes', False), ('two_stage_fc_use_batch_norm', False), ('two_stage_fc_dropout_rate', False), ('CBBCE_predefined_weight', False), ('point_cloud_reconstruction_CBBCE_gaussian_smoothing_std', False), ('point_cloud_reconstruction_dim', False), ('use_lr_scheduler', False), ('use_lr_scheduler_deriv', False), ('cfar_window_size', False), ('beamforming_method', False), ('cfar_os_order_statistic', False), ('cfar_num_censor_cells_largest', False), ('augment_list', False), ('dummy_config', False), ('mvdr_loading_factor', False)])\n",
      "sweep_run_eval: True\n",
      "sweep_run_eval_con_inf: False\n",
      "tensor_board_dir: ../results/temp/temp_2023-07-11_14-46-44_3775404699870012136\n",
      "trainer_name: detection_classification\n",
      "two_stage_fc_dense_batchnorm: None\n",
      "two_stage_fc_dense_dropout: []\n",
      "two_stage_fc_dense_sizes: []\n",
      "two_stage_fc_dense_sizes_sweep_list: [[128, 32], [512, 256, 128], [1024, 256], [512, 64]]\n",
      "two_stage_fc_dims: [[128, 1024], [16, 256], [4, 128]]\n",
      "two_stage_fc_dims_sweep_list: [[[32, 128], [128, 1024], [256, 2048], [64, 512], [16, 256]], [[32, 64], [128, 512], [64, 256], [8, 128]], [[64, 128], [128, 512], [32, 256], [16, 128]], [[128, 1024], [16, 256], [8, 128], [2, 32]], [[128, 1024], [16, 256], [4, 128]]]\n",
      "two_stage_fc_dropout_rate: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "two_stage_fc_dropout_rate_sweep_list: [[0.0, 0.0, 0.0], [0.0, 0.25, 0.0], [0.0, 0.5, 0.0], [0.25, 0.0, 0.25], [0.5, 0.5, 0.5]]\n",
      "two_stage_fc_stdize: True\n",
      "two_stage_fc_use_batch_norm: [False, False, False, False, False, False, False, False, False, False]\n",
      "two_stage_fc_use_batch_norm_sweep_list: [[False, False, False], [True, True, True], [True, False, True], [False, True, False]]\n",
      "two_stage_fc_use_gap: False\n",
      "use_CBBCE: True\n",
      "use_early_stop: True\n",
      "use_lr_scheduler: False\n",
      "use_lr_scheduler_deriv: False\n",
      "use_lr_scheduler_deriv_sweep_list: [True, False]\n",
      "use_lr_scheduler_plateau: True\n",
      "use_lr_scheduler_sweep_list: [True, False]\n",
      "use_model_checkpoint_best: False\n",
      "v_0_max: 7.5\n",
      "v_0_min: -7.5\n",
      "v_r_max: 7.5\n",
      "v_r_min: -7.5\n",
      "without_target_ratio: 1.0\n",
      "without_target_ratio_test: 0.5\n"
     ]
    }
   ],
   "source": [
    "config_properties = list(config)\n",
    "config_properties.sort()\n",
    "\n",
    "for attr_name in config_properties:\n",
    "    attr_value = config[attr_name]\n",
    "    print(f'{attr_name}: {attr_value}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_ipix(config, apply_tf_preprocess_pipe=True, split_data=True, return_dict=False):\n",
    "\n",
    "    if config.ipix_cv_mode:\n",
    "        # load train and validation\n",
    "        data_dict_per_file = {}\n",
    "        cdf_files_list = [f for f in os.listdir(config.ipix_pkl_path_dir) if not f.startswith('.')]\n",
    "        cdf_files_list = [x for x in cdf_files_list if x not in config.ipix_pkl_cv_hold_out]\n",
    "        for cdf_file in cdf_files_list:\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            # read raw data and convert to fast-time x slow-time complex data\n",
    "            c_tensor_total, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            config.r_0_max = rng_bins_ipix[-1]\n",
    "            M_valid = int(config.M_valid / len(cdf_files_list))\n",
    "            M0_valid = int(config.without_target_ratio_test * M_valid)\n",
    "            M1_valid = M_valid\n",
    "            M_train = int(config.M_train / len(cdf_files_list))\n",
    "            M0_train = int(config.without_target_ratio * M_train)\n",
    "            M1_train = M_train\n",
    "            # generate tf.data.Dataset objects\n",
    "            data = {}\n",
    "            c_tensor_total_valid = c_tensor_total[:, int(0.9 * c_tensor_total.shape[1]):]\n",
    "            data['valid'] = gen_ipix_pipeline_dataset(c_tensor_total_valid, clutter_vel, config, M0_valid, M1_valid)\n",
    "\n",
    "            c_tensor_total_train = c_tensor_total[:, :int(0.9 * c_tensor_total.shape[1])]\n",
    "            data['train'] = gen_ipix_pipeline_dataset(c_tensor_total_train, clutter_vel, config, M0_train, M1_train)\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                # add data pipeline functions (maps)\n",
    "                for set_type in ['train', 'valid']:\n",
    "                    data[set_type] = tf_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data\n",
    "\n",
    "        data = {}\n",
    "        for set_type in ['train', 'valid']:\n",
    "            data[set_type] = data_dict_per_file[cdf_files_list[0]][set_type]\n",
    "            for cdf_file in cdf_files_list[1:]:\n",
    "                data[set_type] = data[set_type].concatenate(data_dict_per_file[cdf_file][set_type])\n",
    "\n",
    "        # load test\n",
    "        data_dict_per_file = {}\n",
    "        for cdf_file in config.ipix_pkl_cv_hold_out:\n",
    "            assert cdf_file not in cdf_files_list\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            c_tensor_total_test, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            M_test = int(config.M_test / len(config.ipix_pkl_cv_hold_out))\n",
    "            M0_test = int(config.without_target_ratio_test * M_test)\n",
    "            M1_test = M_test\n",
    "            data['test'] = gen_ipix_pipeline_dataset(c_tensor_total_test, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                data['test'] = tf_dataset_pipeline(config, data['test'])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data['test']\n",
    "\n",
    "        data['test'] = data_dict_per_file[config.ipix_pkl_cv_hold_out[0]]\n",
    "        for cdf_file in config.ipix_pkl_cv_hold_out[1:]:\n",
    "            data['test'] = data['test'].concatenate(data_dict_per_file[cdf_file])\n",
    "\n",
    "    else:\n",
    "\n",
    "        data_dict_per_file = {}\n",
    "        cdf_files_list = [f for f in os.listdir(config.ipix_pkl_path_dir) if not f.startswith('.')]\n",
    "        assert len(cdf_files_list) > 0\n",
    "        # cdf_files_list = ['19980227_221025_ANTSTEP_pol_hh.pkl']\n",
    "        for cdf_file in cdf_files_list:\n",
    "            config.ipix_pkl_path = os.path.join(config.ipix_pkl_path_dir, cdf_file)\n",
    "            # read raw data and convert to fast-time x slow-time complex data\n",
    "            c_tensor_total, rng_bins_ipix, clutter_vel = read_data_ipix(config)\n",
    "            config.r_0_max = rng_bins_ipix[-1]\n",
    "            M_test = int(config.M_test / len(cdf_files_list))\n",
    "            M0_test = int(config.without_target_ratio_test * M_test)\n",
    "            M1_test = M_test\n",
    "            M_valid = int(config.M_valid / len(cdf_files_list))\n",
    "            M0_valid = int(config.without_target_ratio_test * M_valid)\n",
    "            M1_valid = M_valid\n",
    "            M_train = int(config.M_train / len(cdf_files_list))\n",
    "            M0_train = int(config.without_target_ratio * M_train)\n",
    "            M1_train = M_train\n",
    "\n",
    "            # generate tf.data.Dataset objects\n",
    "            data = {}\n",
    "            if split_data:\n",
    "                # test = [0.9, 1.0], valid = [0.85, 0.9], train = [0.0, 0.85]\n",
    "                c_tensor_total_test = c_tensor_total[:,int(0.9 * c_tensor_total.shape[1]):]\n",
    "                data['test'] = gen_ipix_pipeline_dataset(c_tensor_total_test, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "                c_tensor_total_valid = c_tensor_total[:, int(0.85 * c_tensor_total.shape[1]): int(0.9 * c_tensor_total.shape[1])]\n",
    "                data['valid'] = gen_ipix_pipeline_dataset(c_tensor_total_valid, clutter_vel, config, M0_valid, M1_valid)\n",
    "\n",
    "                c_tensor_total_train = c_tensor_total[:, :int(0.85 * c_tensor_total.shape[1])]\n",
    "                data['train'] = gen_ipix_pipeline_dataset(c_tensor_total_train, clutter_vel, config, M0_train, M1_train)\n",
    "            else:\n",
    "                M1_test = config.M_test\n",
    "                M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "                data['test'] = gen_ipix_pipeline_dataset(c_tensor_total, clutter_vel, config, M0_test, M1_test)\n",
    "\n",
    "\n",
    "            if apply_tf_preprocess_pipe:\n",
    "                # add data pipeline functions (maps)\n",
    "                for set_type in ['train', 'valid', 'test']:\n",
    "                    data[set_type] = tf_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "            data_dict_per_file[cdf_file] = data\n",
    "\n",
    "        if return_dict:\n",
    "            return data_dict_per_file\n",
    "        else:\n",
    "            data = {}\n",
    "            for set_type in ['train', 'valid', 'test']:\n",
    "                data[set_type] = data_dict_per_file[cdf_files_list[0]][set_type]\n",
    "                for cdf_file in cdf_files_list[1:]:\n",
    "                    data[set_type] = data[set_type].concatenate(data_dict_per_file[cdf_file][set_type])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_compund_gaussian(config, apply_tf_preprocess_pipe=True):\n",
    "    data = {}\n",
    "    M1_train = config.M_train\n",
    "    M0_train = int(config.M_train * config.without_target_ratio)\n",
    "    M1_valid = config.M_valid\n",
    "    M0_valid = int(config.M_valid * config.without_target_ratio_test)\n",
    "    M1_test = config.M_test\n",
    "    M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "\n",
    "    if config.embedded_target:\n",
    "        assert config.compound_gaussian_single_clutter_vel\n",
    "    data['train'] = gen_compound_gaussian_pipeline_dataset(config, M0_train, M1_train)\n",
    "    data['valid'] = gen_compound_gaussian_pipeline_dataset(config, M0_valid, M1_valid)\n",
    "    data['test'] = gen_compound_gaussian_pipeline_dataset(config, M0_test, M1_test)\n",
    "\n",
    "    if apply_tf_preprocess_pipe:\n",
    "        # add data pipeline functions (maps)\n",
    "        for set_type in ['train', 'valid', 'test']:\n",
    "            data[set_type] = tf_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_wgn(config, apply_tf_preprocess_pipe=True):\n",
    "\n",
    "    data = {}\n",
    "    M1_train = config.M_train\n",
    "    M0_train = int(config.M_train * config.without_target_ratio)\n",
    "    M1_valid = config.M_valid\n",
    "    M0_valid = int(config.M_valid * config.without_target_ratio_test)\n",
    "    M1_test = config.M_test\n",
    "    M0_test = int(config.M_test * config.without_target_ratio_test)\n",
    "\n",
    "    data['train'] = gen_wgn_pipeline_dataset(config, M0_train, M1_train)\n",
    "    data['valid'] = gen_wgn_pipeline_dataset(config, M0_valid, M1_valid)\n",
    "    data['test'] = gen_wgn_pipeline_dataset(config, M0_test, M1_test)\n",
    "\n",
    "    if apply_tf_preprocess_pipe:\n",
    "        # add data pipeline functions (maps)\n",
    "        for set_type in ['train', 'valid', 'test']:\n",
    "            data[set_type] = tf_dataset_pipeline(config, data[set_type])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_output_dim(data, set_type):\n",
    "    if len(list(data['train'].element_spec[1].shape)) > 1:\n",
    "        return [list(data['train'].element_spec[1].shape)[0]]\n",
    "    if type(data[set_type].element_spec[1]) == type(tuple()):\n",
    "        return list(data[set_type].element_spec[1][0].shape)\n",
    "    else:\n",
    "        return [list(data[set_type].element_spec[1].shape)[0]]\n",
    "\n",
    "def get_model_input_dim(data, set_type):\n",
    "    if isinstance(data[set_type].element_spec[0], tuple):\n",
    "        model_input_dim = []\n",
    "        for spec in data[set_type].element_spec[0]:\n",
    "            model_input_dim.append(list(spec.shape))\n",
    "    else:\n",
    "        model_input_dim = list(data[set_type].element_spec[0].shape)\n",
    "\n",
    "    return model_input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_iterators(data, config):\n",
    "\n",
    "    M_train = len(data['train'])\n",
    "    print('make_iterators(): M_train: {}'.format(M_train))\n",
    "    data['train'] = data['train'].shuffle(M_train, reshuffle_each_iteration=True)\n",
    "\n",
    "\n",
    "    train_iter = data['train'].batch(config.batch_size, drop_remainder=True).prefetch(config.batch_size)\n",
    "    valid_iter = data['valid'].batch(config.batch_size)\n",
    "    test_iter = data['test'].batch(config.batch_size)\n",
    "\n",
    "    iterators = {'train': train_iter, 'valid': valid_iter, 'test': test_iter}\n",
    "    return iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config, use_make_iterators=True, apply_tf_preprocess_pipe=True):\n",
    "    model_input_dim_set = 'train'\n",
    "    if config.data_name == \"ipix\":\n",
    "        data = get_dataset_ipix(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "        model_input_dim_set = 'test'\n",
    "    elif config.data_name == \"compound_gaussian\":\n",
    "        data = get_dataset_compund_gaussian(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "        if config.compound_gaussian_add_wgn:\n",
    "            data_wgn = get_dataset_wgn(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "            for key in data.keys():\n",
    "                # rd_signal , label_tensor, (param_val_tensor, scnr_tensor, gamma_shape, clutter_vel, clutter_label_tensor)\n",
    "                data[key] = data[key].map(lambda x0, x1, x2: (x0, x1, (x2[0], x2[1], x2[2], tf.constant(0.0), tf.constant(0.0))))\n",
    "                data[key] = data[key].concatenate(data_wgn[key])\n",
    "    elif config.data_name == \"wgn\":\n",
    "        data = get_dataset_wgn(config, apply_tf_preprocess_pipe=apply_tf_preprocess_pipe)\n",
    "    else:\n",
    "        raise Exception(' ')\n",
    "\n",
    "    # set model_input_dim\n",
    "    config.model_input_dim = get_model_input_dim(data, model_input_dim_set)\n",
    "    config.model_output_dim = get_model_output_dim(data, model_input_dim_set)\n",
    "\n",
    "    if use_make_iterators:\n",
    "        # make data iterators (shuffle,batch,etc.)\n",
    "        data_iterators = make_iterators(data, config)\n",
    "        return config, data_iterators\n",
    "    else:\n",
    "        return config, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_ipix(config):\n",
    "    with open(config.ipix_pkl_path, 'rb') as handle:\n",
    "        ipix_data =pickle.load(handle)\n",
    "        PRI = ipix_data['PRI']\n",
    "        B = ipix_data['B']\n",
    "        rng_bins = ipix_data['rng_bins']\n",
    "        adc_data = ipix_data['adc_data']\n",
    "\n",
    "    rng_bins = rng_bins[:config.ipix_max_nrange_bins]\n",
    "    adc_data = adc_data[:config.ipix_max_nrange_bins, :]\n",
    "    if not config.ipix_file_range_bins:\n",
    "        assert config.N <= len(rng_bins) * 2\n",
    "        adc_data = adc_data[:config.N // 2, :]\n",
    "        rng_bins = rng_bins[:config.N // 2]\n",
    "    else:\n",
    "        config.N = len(rng_bins) * 2\n",
    "    assert config.N == len(rng_bins) * 2\n",
    "    config.T_PRI = PRI\n",
    "    config.B_chirp = B\n",
    "    if '19980205_191043' in config.ipix_pkl_path:\n",
    "        # cut weird zero part of this file\n",
    "        adc_data = adc_data[:, :50000]\n",
    "    # convert to fast-time x slow-time data\n",
    "    rng_bins = rng_bins - rng_bins[0]\n",
    "    config.r_0_max = rng_bins[-1]\n",
    "    clutter_omega_r = ((2 * np.pi) / config.N) * ((2*B) / 3e8) * rng_bins\n",
    "    # workaround to prevent GPU overflow in multiple iterations\n",
    "    try:\n",
    "        clutter_range_steering_tensor = tf.math.exp(-1j * tf.cast(tf.expand_dims(tf.range(config.N, dtype=tf.float32), -1) * tf.expand_dims(clutter_omega_r, 0), dtype=tf.complex128))\n",
    "        c_tensor = clutter_range_steering_tensor @ adc_data\n",
    "    except:\n",
    "        clutter_range_steering_tensor = np.exp(-1j * tf.cast(tf.expand_dims(tf.range(config.N, dtype=tf.float32), -1) * tf.expand_dims(clutter_omega_r, 0), dtype=tf.complex128))\n",
    "        c_tensor = clutter_range_steering_tensor @ adc_data\n",
    "\n",
    "    \"\"\"\n",
    "    estimate clutter Doppler frequency using welch method: \n",
    "        c_tensor[i] = e ^ {j 2 \\pi f_d kT_PRI}\n",
    "        f_d = (2 * f_c * clutter_vel) / c\n",
    "    \"\"\"\n",
    "\n",
    "    Pxx_den_list = []\n",
    "    for i in range(adc_data.shape[0]):\n",
    "        f, Pxx_den = scipy.signal.welch(adc_data[i], 1 / PRI, return_onesided=False)\n",
    "        Pxx_den_list.append(Pxx_den)\n",
    "\n",
    "    PSD = np.mean(np.array(Pxx_den_list), 0)\n",
    "    PSD = PSD / np.max(PSD)\n",
    "    clutter_fd = f[np.argmax(PSD)]\n",
    "    clutter_vel = -(3e8 * clutter_fd) / (2 * 9.39e9)\n",
    "\n",
    "    return c_tensor, rng_bins, clutter_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ipix_pipeline_dataset(c_tensor_total, clutter_vel, config, M0, M1):\n",
    "\n",
    "    def gen_ipix_frame2d(ind):\n",
    "        c_tensor = tf.image.random_crop(c_tensor_total, [config.N, config.K])\n",
    "        clutter_vel_local = clutter_vel\n",
    "        if config.ipix_random_shift_doppler:\n",
    "            shift_min = tf.cast(clutter_vel_local - config.v_r_min, dtype=tf.float32)\n",
    "            shift_max = tf.cast(config.v_r_max - clutter_vel_local, dtype=tf.float32)\n",
    "            doppler_shift_v = tf.cast(tf.random.uniform([], -shift_min, shift_max), dtype=tf.complex128)\n",
    "            clutter_vel_local = clutter_vel + tf.cast(tf.math.real(doppler_shift_v), dtype=tf.float32)\n",
    "            shift_factor = tf.expand_dims(tf.math.exp(-1j * 2 * np.pi * ((2 * config.f_c * doppler_shift_v) / 3e8) * config.T_PRI * tf.cast(tf.range(c_tensor.shape[1]), dtype=tf.complex128) ), 0 )\n",
    "            c_tensor = c_tensor * shift_factor\n",
    "\n",
    "            # fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            # im = ax.imshow(np.log10(tf.signal.fftshift(tf.abs(tf.signal.ifft2d(c_tensor)), axes=(0, 1)))[32:, :], interpolation='none', extent=[np.min(recon_vec_vel), np.max(recon_vec_vel), np.max(recon_vec_rng), np.min(recon_vec_rng)], aspect=\"auto\")\n",
    "            # plt.xlabel(\"Doppler Velocity [m/s]\")\n",
    "            # plt.ylabel(\"Normalized Range [m]\")\n",
    "            # plt.show()\n",
    "        if with_target is False:\n",
    "            param_val_tensor = tf.ones(config.num_targets) * -1000.0, tf.ones(config.num_targets) * -1000.0\n",
    "            return c_tensor, tf.zeros((recon_vec_rng.shape[0], recon_vec_vel.shape[0]), dtype=tf.int64), \\\n",
    "                   param_val_tensor, tf.ones(config.num_targets) * -1000.0, tf.constant(0.0), clutter_vel_local, tf.constant(0.0)\n",
    "        else:\n",
    "            cn_norm = tf.abs(tf.linalg.norm(c_tensor))\n",
    "            rd_signal, label_tensor, param_val_tensor, scnr_tensor = gen_target_matrix(config, cn_norm, clutter_vel_local, N, K, recon_vec_rng, recon_vec_vel)\n",
    "\n",
    "            return rd_signal + c_tensor, label_tensor, param_val_tensor, scnr_tensor, tf.constant(0.0), clutter_vel_local, tf.constant(0.0)\n",
    "\n",
    "    def get_ipix_tfds(M_tfds):\n",
    "        _res = gen_ipix_frame2d(0)\n",
    "        tfds = tf.data.Dataset.range(0, M_tfds).map(gen_ipix_frame2d, num_parallel_calls=-1)\n",
    "\n",
    "        return tfds\n",
    "\n",
    "    assert config.N == c_tensor_total.shape[0]\n",
    "    assert not (config.SCNR_db_random_constant and config.SCNR_db_random_choice)\n",
    "    N = config.N\n",
    "    K = config.K\n",
    "\n",
    "    recon_vec_rng = tf.cast(get_reconstruction_point_cloud_vec(config, param_ind=0), dtype=tf.float32)\n",
    "    recon_vec_vel = tf.cast(get_reconstruction_point_cloud_vec(config, param_ind=1), dtype=tf.float32)\n",
    "\n",
    "    with_target = False\n",
    "    tfds0 = get_ipix_tfds(M0)\n",
    "    with_target = True\n",
    "    tfds1 = get_ipix_tfds(M1)\n",
    "\n",
    "    assert tfds1.element_spec[0] == tfds0.element_spec[0] and tfds1.element_spec[1] == tfds0.element_spec[1]\n",
    "    tfds = tfds1.concatenate(tfds0)\n",
    "    tfds = tfds.map(split_auxillary_structure)\n",
    "\n",
    "\n",
    "    return tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_point_cloud_vec(config, param_ind):\n",
    "\n",
    "    if config.point_cloud_reconstruction_fft_dims:\n",
    "        N = config.point_cloud_reconstruction_fft_dim_factor * config.N\n",
    "        config.B_chirp = config.point_cloud_reconstruction_fft_dim_factor * config.B_chirp # multiply to rescale range dimension\n",
    "        K = config.point_cloud_reconstruction_fft_dim_factor * config.K\n",
    "        L = config.point_cloud_reconstruction_fft_dim_factor * config.L\n",
    "\n",
    "        range_res, vel_res, recon_vec_rng, recon_vec, azimuth_bins_values = get_fft_resolutions(config, [1, N, K, L], T_PRI=config.T_PRI)\n",
    "        bin_values_list, valid_bins_list = get_valid_2d_bins(config, [N, K], recon_vec_rng, recon_vec)\n",
    "        range_bins_values = bin_values_list[0]\n",
    "        vel_bins_values = bin_values_list[1]\n",
    "\n",
    "        config.B_chirp = config.B_chirp /  config.point_cloud_reconstruction_fft_dim_factor\n",
    "        if param_ind == 0:\n",
    "            return range_bins_values\n",
    "        elif param_ind == 1:\n",
    "            return vel_bins_values\n",
    "        else:\n",
    "            raise Exception('  ')\n",
    "    else:\n",
    "        raise Exception('get_reconstruction_point_cloud_res(): Unsupported...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_resolutions(config, data_shape, T_PRI=None):\n",
    "    assert len(data_shape) == 4\n",
    "    T_PRI = data_shape[1] * (1 / config.f_s) + config.T_idle if T_PRI is None else T_PRI\n",
    "    vel_res = 3e8 / (2 * config.f_c * data_shape[2] * T_PRI)\n",
    "    range_res = 3e8 / (2 * config.B_chirp)\n",
    "    range_bins_values = np.array([range_res * (i - data_shape[1] // 2) for i in range(data_shape[1])])\n",
    "    vel_bins_values = np.array([vel_res * (i - data_shape[2] // 2) for i in range(data_shape[2])])\n",
    "\n",
    "    azimuth_bins_values = np.arcsin([(2.0 * (i - data_shape[3] // 2)) / data_shape[3]\n",
    "                                          for i in range(data_shape[3])]) * (180.0 / np.pi)\n",
    "\n",
    "    return range_res, vel_res, range_bins_values, vel_bins_values, azimuth_bins_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_valid_2d_bins(config, full_shape, range_bins_values, vel_bins_values):\n",
    "    assert len(full_shape) == 2\n",
    "    valid_vel_bins = \\\n",
    "    np.where(np.logical_and(vel_bins_values >= config.v_0_min, vel_bins_values <= config.v_0_max))[0]\n",
    "    if valid_vel_bins[-1] < full_shape[1] - 1:\n",
    "        valid_vel_bins = np.append(valid_vel_bins, valid_vel_bins[-1] + 1)\n",
    "    if valid_vel_bins[0] > 0:\n",
    "        valid_vel_bins = np.insert(valid_vel_bins, 0, valid_vel_bins[0] - 1)\n",
    "    vel_bins_values = vel_bins_values[valid_vel_bins]\n",
    "\n",
    "    valid_range_bins = np.where(np.logical_and(range_bins_values >= config.r_0_min, range_bins_values <= config.r_0_max))[0]\n",
    "    # if valid_range_bins[-1] < full_shape[0] - 1:\n",
    "    #     valid_range_bins = np.append(valid_range_bins, valid_range_bins[-1] + 1)\n",
    "    # if valid_range_bins[0] > 0:\n",
    "    #     valid_range_bins = np.insert(valid_range_bins, 0, valid_range_bins[0] - 1)\n",
    "    range_bins_values = range_bins_values[valid_range_bins]\n",
    "\n",
    "    return [range_bins_values, vel_bins_values], [valid_range_bins, valid_vel_bins]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target and label tensors generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This function generates a target matrix along with corresponding labels, parameter values, and SCNR tensors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_target_matrix(config, cn_norm, clutter_vel_local, N, K, recon_vec_rng, recon_vec_vel):\n",
    "\n",
    "    # randomly determine the number of targets or set it to a constant value\n",
    "    if config.random_num_targets:\n",
    "        targets_num = tf.random.uniform([1, ], minval=1, maxval=config.num_targets + 1, dtype=tf.int64)\n",
    "    else:\n",
    "        targets_num = tf.cast(tf.constant([config.num_targets]), dtype=tf.int64)\n",
    "    \n",
    "    # Generate target velocities within specified range considering the presence of embedded targets\n",
    "    if config.embedded_target:\n",
    "        targets_vel = tf.random.uniform(targets_num, tf.maximum(clutter_vel_local - config.embedded_target_vel_offset, config.v_0_min),\n",
    "                                                     tf.minimum(clutter_vel_local + config.embedded_target_vel_offset, config.v_0_max))\n",
    "    else:\n",
    "        targets_vel = tf.random.uniform(targets_num, config.v_0_min, config.v_0_max)\n",
    "    \n",
    "    # Generate target ranges within specified range\n",
    "    targets_rng = tf.random.uniform(targets_num, config.r_0_min, config.r_0_max)\n",
    "    \n",
    "    # compute doppler and range target frequencies\n",
    "    targets_omega_d = tf.cast(2 * np.pi * config.T_PRI * ((2 * config.f_c * targets_vel) / 3e8), dtype=tf.complex128)\n",
    "    targets_omega_r = tf.cast(2 * np.pi * ((2 * config.B_chirp * targets_rng) / (3e8 * N)), dtype=tf.complex128)\n",
    "    \n",
    "    # compute doppler and range steering tensors\n",
    "    doppler_steering_tensor = tf.math.exp(-1j * tf.expand_dims(targets_omega_d, 1) * tf.cast(tf.expand_dims(tf.range(K), 0), dtype=tf.complex128))\n",
    "    range_steering_tensor = tf.math.exp(-1j * tf.expand_dims(targets_omega_r, 1) * tf.cast(tf.expand_dims(tf.range(N), 0), dtype=tf.complex128))\n",
    "    \n",
    "    # compute range-doppler and signal and get the SCNR\n",
    "    rd_signal = tf.expand_dims(range_steering_tensor, 2) * tf.expand_dims(doppler_steering_tensor, 1)\n",
    "    SCNR_db = get_SCNR_db(config, targets_num)\n",
    "    \n",
    "    # Adjust phase of the range-Doppler signal based on the configuration\n",
    "    if config.signal_random_phase:\n",
    "        rd_signal = rd_signal * tf.math.exp(1j * tf.cast(tf.expand_dims(tf.expand_dims(tf.random.uniform(targets_num, 0, 2 * np.pi), 1), 1), dtype=tf.complex128))\n",
    "    elif config.signal_physical_phase:\n",
    "        targets_tau0 = (2 * targets_rng) / 3e8\n",
    "        rd_signal = rd_signal * tf.expand_dims(tf.expand_dims(tf.math.exp(1j * (tf.cast(-2 * np.pi * config.f_c * targets_tau0 + np.pi * (config.B_chirp / (config.N * config.f_s)) * (targets_tau0 ** 2), dtype=tf.complex128))), 1), 1)\n",
    "\n",
    "    # compensate for the appropriate SCNR level\n",
    "    s_norm = tf.math.real(tf.norm(rd_signal, axis=[1, 2]))\n",
    "    sig_amp = (10 ** (tf.cast(SCNR_db, dtype=tf.float64) / 20.0)) * (tf.cast(cn_norm, dtype=tf.float64) / s_norm)\n",
    "    rd_signal = tf.reduce_sum(tf.cast(tf.expand_dims(tf.expand_dims(sig_amp, -1), -1), dtype=tf.complex128) * rd_signal, axis=0)\n",
    "    \n",
    "    # gen label vector\n",
    "    trgt_inds_vel = tf.expand_dims(tf.math.argmin(tf.abs(tf.expand_dims(targets_vel, 1) - tf.expand_dims(recon_vec_vel, 0)), axis=1), 1)\n",
    "    trgt_inds_rng = tf.expand_dims(tf.math.argmin(tf.abs(tf.expand_dims(targets_rng, 1) - tf.expand_dims(recon_vec_rng, 0)), axis=1), 1)\n",
    "    tf.debugging.assert_type(trgt_inds_vel, tf.int64)\n",
    "    tf.debugging.assert_type(trgt_inds_rng, tf.int64)\n",
    "    trgt_inds = tf.concat((trgt_inds_rng, trgt_inds_vel), 1)\n",
    "    tf.debugging.assert_type(trgt_inds, tf.int64)\n",
    "    label_tensor = tf.scatter_nd(trgt_inds, tf.squeeze(tf.ones_like(trgt_inds_vel), 1), (recon_vec_rng.shape[0], recon_vec_vel.shape[0]))\n",
    "\n",
    "    #gen paramter value and SCNR tensor\n",
    "    param_val_tensor = (tf.concat((targets_rng, tf.ones(config.num_targets - targets_num) * -1000.0), axis=0),\n",
    "                        tf.concat((targets_vel, tf.ones(config.num_targets - targets_num) * -1000.0), axis=0))\n",
    "    scnr_tensor = tf.concat((SCNR_db, tf.ones(config.num_targets - targets_num) * -1000.0), axis=0)\n",
    "\n",
    "    return rd_signal, label_tensor, param_val_tensor, scnr_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCNR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***gets the signal to clutter plus noise ratio:***\n",
    "- if config.SCNR_db_random_choice, generates random integers between 0 and the length of config.SCNRs_eval. \n",
    "The SCNR values are gathered from SCNRs_eval using tf.gather() based on the indices in scnr_eval_inds\n",
    "- else if config.SCNR_db_random_constant, a single random SCNR value is chosen from config.SCNRs_eval and repeated for targets_num times.\n",
    "    scnr_eval_inds is generated to select a random index from config.SCNRs_eval.\n",
    "    \n",
    "    The selected SCNR value is multiplied by tf.ones(targets_num) to create a tensor of the same length as targets_num.\n",
    "    The SCNR values are assigned to SCNR_db.\n",
    "- if none of them so a constant SCNR value is used from config.SCNR_db, repeated for targets_num times.\n",
    "\n",
    "    The constant SCNR value is multiplied by tf.ones(targets_num) to create a tensor of the same length as targets_num.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SCNR_db(config, targets_num):\n",
    "\n",
    "    if config.SCNR_db_random_choice:\n",
    "        SCNRs_eval = tf.constant(config.SCNRs_eval, dtype=tf.float32)\n",
    "        scnr_eval_inds = tf.random.uniform(tf.cast(targets_num, dtype=tf.int32), minval=0, maxval=len(config.SCNRs_eval), dtype=tf.int32)\n",
    "        SCNR_db = tf.gather(SCNRs_eval, scnr_eval_inds)\n",
    "    elif config.SCNR_db_random_constant:\n",
    "        SCNRs_eval = tf.constant(config.SCNRs_eval, dtype=tf.float32)\n",
    "        scnr_eval_inds = tf.random.uniform([1], minval=0, maxval=len(config.SCNRs_eval), dtype=tf.int32)\n",
    "        SCNR_db = tf.gather(SCNRs_eval, scnr_eval_inds) * tf.ones(targets_num)\n",
    "    elif config.random_SCNR:\n",
    "        SCNR_db = tf.random.uniform(targets_num, minval=config.SCNR_db_range[0], maxval=config.SCNR_db_range[1] + 0.001)\n",
    "    else:\n",
    "        SCNR_db = tf.constant(config.SCNR_db, dtype=tf.float32) * tf.ones(targets_num)\n",
    "\n",
    "    return SCNR_db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split auxillary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This function removes any 1 sized dimensions from mat_complex, keep mat_label untouched and creates a tuple from the other variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_auxillary_structure(mat_complex, mat_label, param_val, scnr, gamma_shape, clutter_vel, clutter_label_tensor):\n",
    "    return tf.squeeze(mat_complex), mat_label, (param_val, scnr, gamma_shape, clutter_vel, clutter_label_tensor)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This function manages the preprocessing of the data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset_pipeline(config, data):\n",
    "\n",
    "    # centering and reshape mat_complex\n",
    "    def two_stage_fc_preprocess(mat_complex, label):\n",
    "        mat = cube_center_and_reshape(mat_complex)\n",
    "        return mat, label\n",
    "\n",
    "    # standartization: element-wise division by the std \n",
    "    def two_stage_fc_stdize(mat_complex, mat_label, aux):\n",
    "        mat_complex = mat_complex / tf.cast(tf.math.reduce_std(mat_complex, axis=0), dtype=tf.complex128)\n",
    "        return mat_complex, mat_label, aux\n",
    "    \n",
    "    # ????? sends to previous function - why ??????\n",
    "    def two_stage_fc_preprocess_cg(mat_complex, mat_label, aux):\n",
    "        mat_complex, mat_label = two_stage_fc_preprocess(mat_complex, mat_label)\n",
    "        return mat_complex, mat_label, aux\n",
    "\n",
    "    # transpose\n",
    "    def transpose_mat_complex(mat_complex, mat_label, aux):\n",
    "        mat_complex = tf.transpose(mat_complex)\n",
    "        return mat_complex, mat_label, aux\n",
    "\n",
    "    # Concatenates the real and imaginary parts\n",
    "    def concat_real_imag_cg(mat_complex, mat_label, aux):\n",
    "        return tf.concat((tf.math.real(mat_complex), tf.math.imag(mat_complex)), axis=-1), mat_label, aux\n",
    "\n",
    "    # summing along a specified axis (reduce_axis) and then clipping the values to be between 0 and 1\n",
    "    def preprocess_label2d(mat_label):\n",
    "        return tf.cast(tf.clip_by_value(tf.reduce_sum(mat_label, axis=reduce_axis), 0, 1), dtype=tf.float32)\n",
    "\n",
    "    # ?\n",
    "    def cg_preprocess_label_2dims(mat_complex, mat_label, aux):\n",
    "        mat_label = tf.cast(tf.clip_by_value(tf.reduce_sum(mat_label, axis=reduce_axis), 0, 1), dtype=tf.float32)\n",
    "        return mat_complex, mat_label, aux\n",
    "\n",
    "    # squeeze and clip values between 0 and 1\n",
    "    def cg_preprocess_label_1dim(mat_complex, mat_label, aux):\n",
    "        mat_label = tf.squeeze(tf.cast(tf.clip_by_value(mat_label, 0, 1), dtype=tf.float32))\n",
    "        return mat_complex, mat_label, aux\n",
    "\n",
    "    # centers by subtracting the mean of reshaped input along the last axis and then reshapes it back to the original shape. \n",
    "    def cube_center_and_reshape(mat):\n",
    "        mat_center = mat - tf.reduce_mean(tf.reshape(mat, (-1, mat.shape[-1])), axis=0)\n",
    "        return tf.reshape(mat_center, (-1, mat_center.shape[-1]))\n",
    "\n",
    "    '''\n",
    "    if config.data_name is \"ipix\" & config.model_name is \"Detection-TwoStage-FC\":\n",
    "    if config.estimation_params is [\"rng\"], the transpose_mat_complex function is applied to the data\n",
    "    the function is sent to cube_center_and_reshape (from two_stage_fc_preprocess...)\n",
    "    if config.two_stage_fc_stdize is True - it is divided element-wise by the std\n",
    "    we then concatenate the real and imaginary parts, The reduce_axis is set to 1 if config.estimation_params is \"rng\", else 0.\n",
    "    '''\n",
    "    if config.data_name == \"ipix\":\n",
    "        if config.model_name == \"Detection-TwoStage-FC\":\n",
    "            assert config.estimation_params == [\"rng\"] or config.estimation_params == [\"vel\"]\n",
    "            if config.estimation_params == [\"rng\"]:\n",
    "                data = data.map(transpose_mat_complex)\n",
    "            data = data.map(two_stage_fc_preprocess_cg)\n",
    "            if config.two_stage_fc_stdize:\n",
    "               data = data.map(two_stage_fc_stdize)\n",
    "            data = data.map(concat_real_imag_cg)\n",
    "            reduce_axis = 1 if config.estimation_params == [\"rng\"] else 0\n",
    "            data = data.map(cg_preprocess_label_2dims)\n",
    "\n",
    "    \n",
    "    #The first is similar to the previous section:\n",
    "    if config.data_name == \"compound_gaussian\" or config.data_name == \"wgn\":\n",
    "        if config.model_name == \"Detection-TwoStage-FC\":\n",
    "            assert config.estimation_params == [\"rng\"] or config.estimation_params == [\"vel\"]\n",
    "            if config.estimation_params == [\"rng\"]:\n",
    "                data = data.map(transpose_mat_complex)\n",
    "            data = data.map(two_stage_fc_preprocess_cg)\n",
    "            if config.two_stage_fc_stdize:\n",
    "                data = data.map(two_stage_fc_stdize)\n",
    "            data = data.map(concat_real_imag_cg)\n",
    "    # from here comes the difference:\n",
    "    # if config.compound_gaussian_dims is 2, the reduce_axis is set to 1 if config.estimation_params is [\"rng\"],else 0, and the cg_preprocess_label_2dims function is applied to the data.\n",
    "    # if config.compound_gaussian_dims is not 2, we squeeze and clip values between 0 and 1.\n",
    "    # if config.model_name is \"Detection-FC\" and the data is \"compound_gaussian\" or \"wgn\", the lambda function is applied to the data. \n",
    "    # the lambda function concatenates the real and imaginary parts of t along dimension 0, squeezes the label, and performs value clipping between 0 and 1.\n",
    "            if config.compound_gaussian_dims == 2:\n",
    "                reduce_axis = 1 if config.estimation_params == [\"rng\"] else 0\n",
    "                data = data.map(cg_preprocess_label_2dims)\n",
    "            else:\n",
    "                data = data.map(cg_preprocess_label_1dim)\n",
    "        elif config.model_name == \"Detection-FC\":\n",
    "            data = data.map(lambda t, label, aux: (tf.squeeze(tf.concat((tf.math.real(t), tf.math.imag(t)), 0)),\n",
    "                                                   tf.cast(tf.clip_by_value(tf.squeeze(label), 0, 1), dtype=tf.float32), aux))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageFcLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Perform TwoStage Fully-Connected\n",
    "    input tensor: (input_row_dim, input_col_dim)\n",
    "    output tensor: (row_units, column_units)\n",
    "    \"\"\"\n",
    "    def __init__(self, row_units, column_units, l2_lamda, activation_name, use_batchnorm, dropout_rate, is_first, **kwargs):\n",
    "        super(TwoStageFcLayer, self).__init__()\n",
    "\n",
    "        self.row_units = row_units\n",
    "        self.column_units = column_units\n",
    "        self.l2_lamda = l2_lamda\n",
    "        self.activation_name = activation_name\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        if l2_lamda > 0.0:\n",
    "            # kernel_reg = EyeRegularizer() if is_first else tf.keras.regularizers.l2(l2_lamda)\n",
    "            self.col_dense = tf.keras.layers.Dense(column_units,\n",
    "                                bias_regularizer=tf.keras.regularizers.l2(l2_lamda),\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2_lamda))\n",
    "            # kernel_regularizer=kernel_reg)\n",
    "            self.row_dense = tf.keras.layers.Dense(row_units,\n",
    "                                bias_regularizer=tf.keras.regularizers.l2(l2_lamda),\n",
    "                                kernel_regularizer=tf.keras.regularizers.l2(l2_lamda))\n",
    "        else:\n",
    "            self.col_dense = tf.keras.layers.Dense(column_units)\n",
    "            self.row_dense = tf.keras.layers.Dense(row_units)\n",
    "        self.col_activation = Activation(activation_name)\n",
    "        self.row_activation = Activation(activation_name)\n",
    "\n",
    "        if self.use_batchnorm:\n",
    "            self.col_bnorm = tf.keras.layers.BatchNormalization()\n",
    "            self.row_bnorm = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        if self.dropout_rate > 0.0:\n",
    "            self.col_dropout = Dropout(rate=self.dropout_rate)\n",
    "            self.row_dropout = Dropout(rate=self.dropout_rate)\n",
    "        return\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        # input_tensor: [batch, input_row_dim, input_col_dim]\n",
    "\n",
    "        x = self.col_dense(input_tensor) # [batch, input_row_dim, column_units]\n",
    "        x = self.col_activation(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.col_bnorm(x, training=training)\n",
    "        if self.dropout_rate > 0.0:\n",
    "            x = self.col_dropout(x, training=training)\n",
    "\n",
    "        x = tf.transpose(x, perm=[0, 2, 1]) # [batch, column_units, input_row_dim]\n",
    "\n",
    "        x = self.row_dense(x) # [batch, column_units, row_units]\n",
    "        x = self.row_activation(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.row_bnorm(x, training=training)\n",
    "        if self.dropout_rate > 0.0:\n",
    "            x = self.row_dropout(x, training=training)\n",
    "\n",
    "        x = tf.transpose(x, perm=[0, 2, 1]) # [batch, row_units, col_units]\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TwoStageFCModel(config, include_top=True, name_str=\"\"):\n",
    "    l2_lamda = config.l2_reg_parameter\n",
    "    two_stage_fc_dims = config.two_stage_fc_dims\n",
    "    two_stage_fc_use_batch_norm = config.two_stage_fc_use_batch_norm\n",
    "    two_stage_fc_dropout_rate = config.two_stage_fc_dropout_rate\n",
    "    activation_name = config.activation\n",
    "    input_layer = Input(shape=config.model_input_dim, name=\"input\")\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(len(two_stage_fc_dims)):\n",
    "        is_first = True if i==0 else False\n",
    "        x = TwoStageFcLayer(row_units=two_stage_fc_dims[i][0], column_units=two_stage_fc_dims[i][1], l2_lamda=l2_lamda,\n",
    "                             activation_name=activation_name,\n",
    "                             use_batchnorm=two_stage_fc_use_batch_norm[i], dropout_rate=two_stage_fc_dropout_rate[i], is_first=is_first)(x)\n",
    "    if config.two_stage_fc_use_gap:\n",
    "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    else:\n",
    "        x = Flatten()(x)\n",
    "\n",
    "    config.dense_sizes = config.two_stage_fc_dense_sizes\n",
    "    config.dense_dropout = config.two_stage_fc_dense_dropout\n",
    "    config.fc_batchnorm = config.two_stage_fc_dense_batchnorm\n",
    "    if config.dense_sizes != []:\n",
    "        x = FCSkeletonModel(config, x, create_model=False)\n",
    "\n",
    "    if config.point_cloud_reconstruction:\n",
    "        last_layer_dim = config.model_output_dim[0]\n",
    "    elif config.mode == \"Estimation\":\n",
    "        last_layer_dim = len(config.estimation_params)\n",
    "    elif config.mode == \"Detection\":\n",
    "        last_layer_dim = 2\n",
    "    else:\n",
    "        raise Exception(\"TwoStageFCModel(): Unsupported config.mode\")\n",
    "\n",
    "    if l2_lamda > 0:\n",
    "        y_hat = Dense(last_layer_dim,\n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2_lamda),\n",
    "                  bias_regularizer=tf.keras.regularizers.l2(l2_lamda))(x)\n",
    "    else:\n",
    "        y_hat = Dense(last_layer_dim)(x)\n",
    "\n",
    "    if config.point_cloud_reconstruction:\n",
    "        y_hat = activation(config, 'sigmoid', y_hat)\n",
    "    elif config.mode == \"Detection\":\n",
    "        y_hat = activation(config, 'softmax', y_hat)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=y_hat, name=\"TwoStageFcModel\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def activation(config, activation_name, x):\n",
    "    if activation_name == 'leaky_relu':\n",
    "        return LeakyReLU(alpha=config.leaky_alpha)(x)\n",
    "    else:\n",
    "        return Activation(activation_name)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FCSkeletonModel(config, input_layer, create_model=True, output_name=\"\", dense_activations=None):\n",
    "\n",
    "    # get parameters from config file\n",
    "    dense_sizes = config.dense_sizes\n",
    "    dense_dropout = [0 for _ in range(len(dense_sizes))] if config.dense_dropout is None else config.dense_dropout\n",
    "    activation_name = config.activation\n",
    "    if dense_activations == None:\n",
    "        dense_activations = [activation_name for j in range(len(dense_sizes))]\n",
    "    else:\n",
    "        assert len(dense_activations) == len(dense_sizes)\n",
    "    l2_lamda = config.l2_reg_parameter\n",
    "\n",
    "    x = input_layer\n",
    "    # Dense\n",
    "    for i, size in enumerate(dense_sizes):\n",
    "        if l2_lamda != 0:\n",
    "            x = Dense(size, kernel_regularizer=tf.keras.regularizers.l2(l2_lamda),\n",
    "                      bias_regularizer=tf.keras.regularizers.l2(l2_lamda))(x)\n",
    "        else:\n",
    "            x = Dense(size)(x)\n",
    "        if dense_activations[i] != \"None\":\n",
    "            x = activation(config, dense_activations[i], x)\n",
    "        if config.fc_batchnorm:\n",
    "            x = BatchNormalization()(x)\n",
    "        # Dropout, at the last layer apply dropout after flatten\n",
    "        if dense_dropout[i] != 0:\n",
    "            x = Dropout(rate=dense_dropout[i])(x)\n",
    "\n",
    "    output_layer = x\n",
    "    if create_model:\n",
    "        model = Model(input_layer, output_layer)\n",
    "        if output_name!= \"\":\n",
    "            model.layers[len(model.layers) - 1]._name = output_name\n",
    "        return model\n",
    "    else:\n",
    "        return output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimationFCModel(config):\n",
    "    input_layer = Input(shape=config.model_input_dim)\n",
    "    l2_lamda = config.l2_reg_parameter\n",
    "\n",
    "    model_fc_skeleton = FCSkeletonModel(config, input_layer)\n",
    "    x = model_fc_skeleton.output\n",
    "\n",
    "    # prediction neuron\n",
    "    output_layer = Dense(len(config.estimation_params),\n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(l2_lamda),\n",
    "                         bias_regularizer=tf.keras.regularizers.l2(l2_lamda))(x)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, output_layer, name=\"EstimationFCModel\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(config):\n",
    "    if config.load_complete_model:\n",
    "        model = tf.keras.models.load_model(config.load_model_path, compile=False)\n",
    "        print(\"\\n\" + \"!\" * 25 + \"\\n\" + \"WARNING: LOADING MODEL FROM: {}\".format(config.load_model_path) + \"\\n\" + \"!\" * 25 + \"\\n\")\n",
    "    elif config.model_name == \"Estimation-FC\":\n",
    "        model = EstimationFCModel(config)\n",
    "    elif config.model_name == \"Estimation-TwoStage-FC\" or config.model_name == \"Detection-TwoStage-FC\":\n",
    "         model = TwoStageFCModel(config)\n",
    "    else:\n",
    "        raise ValueError(\"'{}' is an invalid model name\")\n",
    "\n",
    "    model.summary(line_length=140)\n",
    "    if config.load_complete_model:\n",
    "        print(\"\\n\" + \"!\" * 25 + \"\\n\" + \"WARNING: LOADING MODEL FROM: {}\".format(config.load_model_path) + \"\\n\" + \"!\" * 25 + \"\\n\")\n",
    "    try:\n",
    "        model_plot_dir = os.path.join(config.tensor_board_dir, \"model_plot\")\n",
    "        if not os.path.exists(model_plot_dir):\n",
    "            os.makedirs(model_plot_dir)\n",
    "        img_pth = os.path.join(model_plot_dir, config.model_name + \".png\")\n",
    "        plot_model(model, img_pth, show_shapes=False)\n",
    "        print(\"saved model plot at: {}\".format(img_pth))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to plot model:\" + str(e))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, gamma=5):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        return\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        _nll2 = tf.keras.losses.binary_crossentropy(tf.expand_dims(y_true, -1), tf.expand_dims(y_pred, -1))\n",
    "        pt = tf.zeros_like(_nll2)\n",
    "        # pt for y_true == 1\n",
    "        ind1 = tf.where(y_true >= 0.999)\n",
    "        pt1 = tf.gather_nd(y_pred, ind1)\n",
    "        pt = tf.tensor_scatter_nd_update(pt, ind1, pt1)\n",
    "        # pt for y_true == 0\n",
    "        ind0 = tf.where(y_true < 0.999)\n",
    "        pt0 = 1 - tf.gather_nd(y_pred, ind0)\n",
    "        pt = tf.tensor_scatter_nd_update(pt, ind0, pt0)\n",
    "        # compute Focal Loss\n",
    "        loss = tf.math.pow(1 - pt, self.gamma) * _nll2\n",
    "\n",
    "        return tf.reduce_mean(loss, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassBalancedBinaryCrossEntropy(tf.keras.losses.Loss):\n",
    "    def __init__(self, e1, e0, predefined_weight, use_penalize_margin=False, penalize_margin=8, balanced_loss_beta=0.99, recon_dim=128):\n",
    "        super().__init__()\n",
    "        self.balanced_loss_beta = balanced_loss_beta\n",
    "        self.e1 = e1\n",
    "        self.e0 = e0\n",
    "        self.predefined_weight = predefined_weight\n",
    "        self.use_penalize_margin = use_penalize_margin\n",
    "        self.penalize_margin = penalize_margin\n",
    "\n",
    "        if self.predefined_weight > 0.0:\n",
    "            self.weight0 = 1.0\n",
    "            self.weight1 = self.predefined_weight\n",
    "        else:\n",
    "            self.weight0 = ((1.0 - self.balanced_loss_beta) / (1.0 - self.balanced_loss_beta ** self.e0))\n",
    "            self.weight1 = ((1.0 - self.balanced_loss_beta) / (1.0 - self.balanced_loss_beta ** self.e1))\n",
    "\n",
    "        if self.use_penalize_margin:\n",
    "            assert self.penalize_margin > 1\n",
    "            self.ind1_getter = self.get_ind1_with_margin\n",
    "        else:\n",
    "            self.ind1_getter = self.get_ind1\n",
    "\n",
    "        self.label_map = lambda y_true: y_true\n",
    "\n",
    "        self.recon_dim = recon_dim\n",
    "\n",
    "\n",
    "    def get_ind1(self, y_true):\n",
    "        ind1 = tf.where(y_true >= 0.9999)\n",
    "        return ind1\n",
    "\n",
    "    def get_ind1_with_margin(self, y_true):\n",
    "        def get_ind_margin_inds(t):\n",
    "            # t = tf.where(y_true >= 0.9999)[0]\n",
    "            ind_plus = tf.concat((tf.expand_dims(tf.gather(t, 0) * tf.cast(tf.ones(self.penalize_margin), dtype=tf.int64), 1),\n",
    "                 tf.expand_dims(tf.minimum(tf.gather(t, 1) + tf.range(self.penalize_margin, dtype=tf.int64), self.recon_dim - 1), 1)), axis=1)\n",
    "            ind_minus = tf.concat((tf.expand_dims(tf.gather(t, 0) * tf.cast(tf.ones(self.penalize_margin - 1), dtype=tf.int64), 1),\n",
    "                 tf.expand_dims(tf.maximum(tf.gather(t, 1) - tf.range(1, self.penalize_margin, dtype=tf.int64), 0), 1)), axis=1)\n",
    "\n",
    "            return tf.concat((ind_plus, ind_minus), axis=0)\n",
    "        ind1 = tf.reshape(tf.map_fn(get_ind_margin_inds, tf.where(y_true > 0.9999)),(-1, 2))\n",
    "        return ind1\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # call function for the regular single-label tensor\n",
    "        # y_true = [batch_dim, recon_dim], y_pred = [batch_dim, recon_dim]\n",
    "        ind1 = self.ind1_getter(y_true)\n",
    "        # y_true = self.label_map(y_true)\n",
    "        _nll2 = tf.keras.losses.binary_crossentropy(tf.expand_dims(self.label_map(y_true), -1), tf.expand_dims(y_pred, -1))\n",
    "        _nll_subset = self.weight1 * tf.gather_nd(_nll2, ind1)\n",
    "        _nll2 = tf.tensor_scatter_nd_update(_nll2, ind1, _nll_subset)\n",
    "\n",
    "        return tf.reduce_mean(_nll2, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBBCE_get_n0_n1(config, data):\n",
    "    if len(data['train'].element_spec[1].shape) == 1:\n",
    "        n_total = len(data['train']) * data['train'].element_spec[1].shape[0]\n",
    "        n1 = sum([len(np.where(y >= 0.9999)[0]) for X, y, aux in data['train'].as_numpy_iterator()])\n",
    "        n0 = n_total - n1\n",
    "        return n0, n1, n_total, None\n",
    "\n",
    "    else:\n",
    "        n_total = data['train'].element_spec[1].shape[0] * data['train'].element_spec[1].shape[1] * len(data['train'])\n",
    "        if len(list(data['train'].element_spec[1].shape)) == 3:\n",
    "            n1 = sum([len(np.where(y[:, :, 0] >= 0.9999)[0]) for X, y, aux in data['train'].as_numpy_iterator()])\n",
    "        else:\n",
    "            n1 = sum([len(np.where(y >= 0.9999)[0]) for X, y, aux in data['train'].as_numpy_iterator()])\n",
    "        n0 = n_total - n1\n",
    "\n",
    "    return n0, n1, n_total, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasTrainer(object):\n",
    "    \"\"\"\n",
    "    General Keras Trainer class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, data, config, sweep_string=None):\n",
    "        self.model_train = model\n",
    "        # self.model_eval = model['eval']\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "        self.exp_name_time = config.exp_name_time\n",
    "        self.sweep_string = sweep_string\n",
    "        self.callback_list = []\n",
    "        self.optimizer = self.get_optimizer(config.optimizer)\n",
    "\n",
    "    def get_optimizer(self, name):\n",
    "        if name == \"adam\":\n",
    "            return Adam(learning_rate=self.config.learning_rate)\n",
    "        else:\n",
    "            raise Exception('Unsupported optimizer !!')\n",
    "\n",
    "    def add_callbacks(self):\n",
    "        self.callback_list = []\n",
    "        checkpoint_dir = os.path.join(self.config.tensor_board_dir, 'checkpoints')\n",
    "        checkpoint_best_filepath = os.path.join(checkpoint_dir, 'model_checkpoint_best')\n",
    "        checkpoint_epoch_filepath = os.path.join(checkpoint_dir, 'model_checkpoint_epoch')\n",
    "        # Save best Epoch model\n",
    "        if self.config.use_model_checkpoint_best:\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            # save best model\n",
    "            save_model_best_callback = ModelCheckpoint(filepath=checkpoint_best_filepath, save_weights_only=False,\n",
    "                                                       monitor=self.config.model_checkpoint_best_metric,\n",
    "                                                       save_best_only=True, verbose=1)\n",
    "            self.callback_list.append(save_model_best_callback)\n",
    "\n",
    "        # Save model periodically\n",
    "        if self.config.model_checkpoint_epoch_period > 0:\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            # save model periodically\n",
    "            save_model_epoch_callback = ModelCheckpoint(filepath=checkpoint_epoch_filepath, save_weights_only=False,\n",
    "                                                        save_best_only=False, verbose=1)\n",
    "            self.callback_list.append(save_model_epoch_callback)\n",
    "\n",
    "        # CSV Logger for per-epoch logging\n",
    "        if self.config.save_fit_history:\n",
    "            fit_log_dir = os.path.join(self.config.tensor_board_dir, 'fit_log')\n",
    "            if not os.path.exists(fit_log_dir):\n",
    "                os.makedirs(fit_log_dir)\n",
    "            if self.sweep_string is None:\n",
    "                csv_logger_path = os.path.join(fit_log_dir, '{}_fit_log.csv'.format(self.config.exp_name_time))\n",
    "            else:\n",
    "                csv_logger_path = os.path.join(fit_log_dir,\n",
    "                                               '{}_fit_log.csv'.format(self.sweep_string))\n",
    "            csv_logger = CSVLogger(csv_logger_path)\n",
    "            self.callback_list.append(csv_logger)\n",
    "\n",
    "        # Early-Stopping\n",
    "        if self.config.use_early_stop:\n",
    "            # patiennce_epochs = int(self.config.early_stop_patience*self.config.num_epochs) if self.config.early_stop_patience<=1 else self.config.early_stop_patience\n",
    "            # early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor=self.config.early_stop_metric, verbose=1, patience=patiennce_epochs)\n",
    "            early_stop_callback = EarlyStoppingCallback(self.config)\n",
    "            self.callback_list.append(early_stop_callback)\n",
    "\n",
    "        if self.config.use_lr_scheduler:\n",
    "            assert not self.config.use_lr_scheduler_deriv\n",
    "            lr_scheduler = LrScheduler(self.config)\n",
    "            lr_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler.schedule)\n",
    "            self.callback_list.append(lr_scheduler_callback)\n",
    "        if self.config.use_lr_scheduler_plateau:\n",
    "            assert not self.config.use_lr_scheduler_deriv\n",
    "            assert not self.config.use_lr_scheduler\n",
    "            lr_scheduler_plateau = LrSchedulerPlateau(self.config)\n",
    "            self.callback_list.append(lr_scheduler_plateau)\n",
    "\n",
    "        if self.config.use_lr_scheduler_deriv:\n",
    "            assert not self.config.use_lr_scheduler\n",
    "            lr_scheduler_callback = LrSchedulerDeriv(self.config)\n",
    "            self.callback_list.append(lr_scheduler_callback)\n",
    "\n",
    "        if self.config.stop_max_acc:\n",
    "            callback_obj = StoppingAtMaxAccuracy()\n",
    "            self.callback_list.append(callback_obj)\n",
    "\n",
    "        self.callback_list = None if self.callback_list == [] else self.callback_list\n",
    "        return\n",
    "\n",
    "    def compile(self, loss_fn, metrics):\n",
    "        # compile the model\n",
    "        self.model_train.compile(optimizer=self.optimizer, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "    def train(self):\n",
    "        # # model checkpoints for\n",
    "        # self.add_callbacks()\n",
    "\n",
    "        # train the model\n",
    "        history = self.model_train.fit(self.data['train'], epochs=self.config.num_epochs,\n",
    "                                       validation_data=self.data['valid'],\n",
    "                                       callbacks=self.callback_list,\n",
    "                                       verbose=self.config.fit_verbose)\n",
    "        return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_binary_cross_entropy(y_true, y_pred):\n",
    "    ind1 = tf.where(y_true >= 0.9999)\n",
    "    value = tf.cond(tf.size(ind1)==0, lambda: tf.constant(0.0),\n",
    "            lambda :tf.reduce_mean(metrics.binary_crossentropy(tf.expand_dims(tf.gather_nd(y_true, ind1), -1),\n",
    "                                               tf.expand_dims(tf.gather_nd(y_pred, ind1), -1)), axis=-1))\n",
    "    return value\n",
    "def negative_binary_cross_entropy(y_true, y_pred):\n",
    "    ind0 = tf.where(y_true < 0.9999)\n",
    "    value = tf.reduce_mean(metrics.binary_crossentropy(tf.expand_dims(tf.gather_nd(y_true, ind0), -1),\n",
    "                                                       tf.expand_dims(tf.gather_nd(y_pred, ind0), -1)), axis=-1)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTrainerKeras(KerasTrainer):\n",
    "\n",
    "    def __init__(self, model, data, config, sweep_string=None):\n",
    "        super().__init__(model, data, config, sweep_string)\n",
    "        # tf.config.experimental_run_functions_eagerly(True)\n",
    "        assert config.data_name == \"compound_gaussian\" or config.data_name == \"ipix\" or config.data_name == \"wgn\"\n",
    "        self.sweep_string = '' if sweep_string is None else sweep_string\n",
    "        tune_hist_dir = os.path.join(self.config.tensor_board_dir, 'tune_hist')\n",
    "        if not os.path.exists(tune_hist_dir):\n",
    "            os.makedirs(tune_hist_dir)\n",
    "        self.tune_hist_path = os.path.join(tune_hist_dir, 'tune_hist_' + self.sweep_string + '.csv')\n",
    "        assert config.point_cloud_reconstruction\n",
    "        if self.config.use_CBBCE:\n",
    "            n0, n1, n_total, n2 = CBBCE_get_n0_n1(config, data)\n",
    "            self.loss_fn = ClassBalancedBinaryCrossEntropy(e0=n0 / n_total, e1=n1 / n_total,\n",
    "                predefined_weight=self.config.CBBCE_predefined_weight,\n",
    "                use_penalize_margin=self.config.CBBCE_use_penalize_margin, penalize_margin=self.config.CBBCE_penalize_margin,\n",
    "                recon_dim=self.config.model_output_dim[0])\n",
    "        else:\n",
    "            self.loss_fn = FocalLoss()\n",
    "\n",
    "        self.metrics = [metrics.binary_crossentropy, positive_binary_cross_entropy, negative_binary_cross_entropy,\n",
    "                    metrics.AUC(name='auc'), 'accuracy', metrics.FalsePositives(name=\"fp\"), metrics.TruePositives(name=\"tp\")]\n",
    "\n",
    "    def train(self):\n",
    "        # super().compile(self.loss_fn, self.metrics)\n",
    "        self.model_train.compile(optimizer=self.optimizer, loss=self.loss_fn, metrics=self.metrics)\n",
    "        super().add_callbacks()\n",
    "\n",
    "        # train the model\n",
    "        data_train = self.data['train']\n",
    "        data_valid = self.data['valid']\n",
    "\n",
    "        if self.config.data_name == \"compound_gaussian\" or self.config.data_name == \"ipix\" or self.config.data_name == \"wgn\":\n",
    "            data_train = data_train.map(compound_gaussian_split_aux_trainer)\n",
    "            data_valid = data_valid.map(compound_gaussian_split_aux_trainer)\n",
    "\n",
    "        history = self.model_train.fit(data_train, epochs=self.config.num_epochs, validation_data=data_valid, callbacks=self.callback_list, verbose=self.config.fit_verbose)\n",
    "        return history\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        eval_res = self.model_train.evaluate(self.data['valid'])\n",
    "        return eval_res\n",
    "\n",
    "    def test(self):\n",
    "        test_res = self.model_train.evaluate(self.data['test'])\n",
    "        return test_res\n",
    "\n",
    "    def train_eval(self):\n",
    "        return self.model_train.evaluate(self.data['train'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_train.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trainer(model, data, config, sweep_string=None):\n",
    "    if config.trainer_name == \"detection_classification\":\n",
    "        trainer = ClassificationTrainerKeras(model, data, config, sweep_string)\n",
    "    else:\n",
    "        raise ValueError(\"'{}' is an invalid model name\")\n",
    "\n",
    "    return trainer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nect step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LrSchedulerPlateau(Callback):\n",
    "    def __init__(self, config):\n",
    "        super(LrSchedulerPlateau, self).__init__()\n",
    "        self.decay = config.lr_scheduler_plateau_decay\n",
    "        self.ma_window = config.lr_scheduler_plateau_window + 1\n",
    "        self.cooldown = config.lr_scheduler_plateau_cooldown\n",
    "        self.epoch_threshold = int(config.lr_scheduler_plateau_epoch_threshold * config.num_epochs)\n",
    "        self.val_loss_buffer = []\n",
    "        self.last_update_epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # first epoch is 0\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "        self.val_loss_buffer.append(val_loss)\n",
    "\n",
    "        if epoch > self.epoch_threshold and epoch > self.ma_window + 1:\n",
    "            val_loss_mean = np.mean(self.val_loss_buffer[-self.ma_window:-1])\n",
    "            if (val_loss - val_loss_mean > 1e-4) and (epoch - self.last_update_epoch > self.cooldown) :\n",
    "                self.model.optimizer.learning_rate = self.model.optimizer.learning_rate * self.decay\n",
    "                self.last_update_epoch = epoch\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LrScheduler(object):\n",
    "    def __init__(self, config):\n",
    "        self.decay = config.lr_scheduler_decay\n",
    "        self.period = config.lr_scheduler_period\n",
    "        self.epoch_threshold = int(config.lr_scheduler_epoch_threshold * config.num_epochs)\n",
    "\n",
    "    def schedule(self, epoch, lr):\n",
    "        if epoch < self.epoch_threshold:\n",
    "            return lr\n",
    "        else:\n",
    "            if epoch % self.period == 0:\n",
    "                return self.decay * lr\n",
    "            else:\n",
    "                return lr\n",
    "\n",
    "class EarlyStoppingCallback(Callback):\n",
    "    def __init__(self, config):\n",
    "        super(EarlyStoppingCallback, self).__init__()\n",
    "        self.metric = config.early_stop_metric\n",
    "        self.epoch_patience = int(config.early_stop_patience*config.num_epochs) if config.early_stop_patience<=1 else config.early_stop_patience\n",
    "        self.val_loss_buffer = []\n",
    "        self.stopped_epoch = None\n",
    "\n",
    "        return\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "        self.val_loss_buffer.append(val_loss)\n",
    "\n",
    "        if epoch > self.epoch_patience + 1:\n",
    "            val_loss_diff = self.val_loss_buffer[-1] - self.val_loss_buffer[-self.epoch_patience]\n",
    "            if val_loss_diff > 1e-4:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch is not None:\n",
    "            print(\"EarlyStoppingCallback(): Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "        return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_iterators(): M_train: 19988\n"
     ]
    }
   ],
   "source": [
    "config, data = load_data(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TwoStageFcModel\"\n",
      "____________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                                  Output Shape                                            Param #              \n",
      "============================================================================================================================================\n",
      " input (InputLayer)                                            [(None, 54, 128)]                                       0                    \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer_3 (TwoStageFcLayer)                        (None, 128, 1024)                                       139136               \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer_4 (TwoStageFcLayer)                        (None, 16, 256)                                         264464               \n",
      "                                                                                                                                            \n",
      " two_stage_fc_layer_5 (TwoStageFcLayer)                        (None, 4, 128)                                          32964                \n",
      "                                                                                                                                            \n",
      " flatten_1 (Flatten)                                           (None, 512)                                             0                    \n",
      "                                                                                                                                            \n",
      " dense_13 (Dense)                                              (None, 63)                                              32319                \n",
      "                                                                                                                                            \n",
      " activation_13 (Activation)                                    (None, 63)                                              0                    \n",
      "                                                                                                                                            \n",
      "============================================================================================================================================\n",
      "Total params: 468883 (1.79 MB)\n",
      "Trainable params: 468883 (1.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "____________________________________________________________________________________________________________________________________________\n",
      "Failed to plot model:name 'plot_model' is not defined\n"
     ]
    }
   ],
   "source": [
    "model = build_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "trainer = build_trainer(model, data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound_gaussian_split_aux_trainer(mat, label, aux):\n",
    "    return mat, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\n",
      "Epoch 1: saving model to ../results/temp/temp_2023-07-11_14-46-44_3775404699870012136/checkpoints/model_checkpoint_epoch\n",
      "INFO:tensorflow:Assets written to: ../results/temp/temp_2023-07-11_14-46-44_3775404699870012136/checkpoints/model_checkpoint_epoch/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/temp/temp_2023-07-11_14-46-44_3775404699870012136/checkpoints/model_checkpoint_epoch/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 - 28s - loss: 1.4326 - binary_crossentropy: 0.6961 - positive_binary_cross_entropy: 0.6632 - negative_binary_cross_entropy: 0.6973 - auc: 0.5702 - accuracy: 0.0232 - fp: 638883.0000 - tp: 26703.0000 - val_loss: 1.5388 - val_binary_crossentropy: 0.6813 - val_positive_binary_cross_entropy: 0.5969 - val_negative_binary_cross_entropy: 0.6854 - val_auc: 0.6881 - val_accuracy: 0.0553 - val_fp: 42029.0000 - val_tp: 3125.0000 - 28s/epoch - 354ms/step\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelCheckpoint, CSVLogger, Callback\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[0;32mIn[123], line 38\u001b[0m, in \u001b[0;36mClassificationTrainerKeras.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     data_train \u001b[39m=\u001b[39m data_train\u001b[39m.\u001b[39mmap(compound_gaussian_split_aux_trainer)\n\u001b[1;32m     36\u001b[0m     data_valid \u001b[39m=\u001b[39m data_valid\u001b[39m.\u001b[39mmap(compound_gaussian_split_aux_trainer)\n\u001b[0;32m---> 38\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_train\u001b[39m.\u001b[39;49mfit(data_train, epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_epochs, validation_data\u001b[39m=\u001b[39;49mdata_valid, callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallback_list, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mfit_verbose)\n\u001b[1;32m     39\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, Callback\n",
    "history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
